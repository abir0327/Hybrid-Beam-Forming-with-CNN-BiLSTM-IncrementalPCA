{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "74RO5kRecKFj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "from numpy import genfromtxt\n",
        "import numpy as np\n",
        "\n",
        "def Th_comp_matmul(Ar, Ai, Br, Bi):  # Complex matmul pytorch function ########\n",
        "    if Ar.ndim == 3 and Br.ndim == 3:\n",
        "        a_th = torch.cat((torch.cat((Ar, -Ai), dim=2), torch.cat((Ai, Ar), dim=2)), dim=1)\n",
        "        b_th = torch.cat((torch.cat((Br, -Bi), dim=2), torch.cat((Bi, Br), dim=2)), dim=1)\n",
        "        c_th = torch.matmul(a_th, b_th)\n",
        "        c_th_r = c_th[:, 0:int(c_th.shape[1] / 2), 0:int(c_th.shape[2] / 2)]\n",
        "        c_th_i = c_th[:, int(c_th.shape[1] / 2):, 0:int(c_th.shape[2] / 2)]\n",
        "    elif Ar.ndim == 2 and Br.ndim == 2:\n",
        "        a_th = torch.cat((torch.cat((Ar, -Ai), dim=1), torch.cat((Ai, Ar), dim=1)), dim=0)\n",
        "        b_th = torch.cat((torch.cat((Br, -Bi), dim=1), torch.cat((Bi, Br), dim=1)), dim=0)\n",
        "        c_th = torch.matmul(a_th, b_th)\n",
        "        c_th_r = c_th[0:int(c_th.shape[0] / 2), 0:int(c_th.shape[1] / 2)]\n",
        "        c_th_i = c_th[int(c_th.shape[0] / 2):, 0:int(c_th.shape[1] / 2)]\n",
        "    elif Ar.ndim == 4 and Br.ndim == 4:\n",
        "        a_th = torch.cat((torch.cat((Ar, -Ai), dim=3), torch.cat((Ai, Ar), dim=3)), dim=2)\n",
        "        b_th = torch.cat((torch.cat((Br, -Bi), dim=3), torch.cat((Bi, Br), dim=3)), dim=2)\n",
        "        c_th = torch.matmul(a_th, b_th)\n",
        "        c_th_r = c_th[:, :, 0:int(c_th.shape[2] / 2), 0:int(c_th.shape[3] / 2)]\n",
        "        c_th_i = c_th[:, :, int(c_th.shape[2] / 2):, 0:int(c_th.shape[3] / 2)]\n",
        "    elif Ar.ndim == 5 and Br.ndim == 5:\n",
        "        a_th = torch.cat((torch.cat((Ar, -Ai), dim=4), torch.cat((Ai, Ar), dim=4)), dim=3)\n",
        "        b_th = torch.cat((torch.cat((Br, -Bi), dim=4), torch.cat((Bi, Br), dim=4)), dim=3)\n",
        "        c_th = torch.matmul(a_th, b_th)\n",
        "        c_th_r = c_th[:, :, :, 0:int(c_th.shape[3] / 2), 0:int(c_th.shape[4] / 2)]\n",
        "        c_th_i = c_th[:, :, :, int(c_th.shape[3] / 2):, 0:int(c_th.shape[4] / 2)]\n",
        "    elif Ar.ndim * Br.ndim == 12:\n",
        "        if Ar.ndim == 4:\n",
        "            a_th = torch.cat((torch.cat((Ar, -Ai), dim=3), torch.cat((Ai, Ar), dim=3)), dim=2)\n",
        "            b_th = torch.cat((torch.cat((Br, -Bi), dim=2), torch.cat((Bi, Br), dim=2)), dim=1)\n",
        "          \n",
        "            c_th = torch.matmul(a_th, b_th)\n",
        "            c_th_r = c_th[:, :, 0:int(c_th.shape[2] / 2), 0:int(c_th.shape[3] / 2)]\n",
        "            c_th_i = c_th[:, :, int(c_th.shape[2] / 2):, 0:int(c_th.shape[3] / 2)]\n",
        "        elif Br.ndim == 4:\n",
        "            a_th = torch.cat((torch.cat((Ar, -Ai), dim=2), torch.cat((Ai, Ar), dim=2)), dim=1)\n",
        "            b_th = torch.cat((torch.cat((Br, -Bi), dim=3), torch.cat((Bi, Br), dim=3)), dim=2)\n",
        "            c_th = torch.matmul(a_th, b_th)\n",
        "            c_th_r = c_th[:, :, 0:int(c_th.shape[2] / 2), 0:int(c_th.shape[3] / 2)]\n",
        "            c_th_i = c_th[:, :, int(c_th.shape[2] / 2):, 0:int(c_th.shape[3] / 2)]\n",
        "    elif Ar.ndim * Br.ndim == 20:\n",
        "        if Ar.ndim == 5:\n",
        "            a_th = torch.cat((torch.cat((Ar, -Ai), dim=4), torch.cat((Ai, Ar), dim=4)), dim=3)\n",
        "            b_th = torch.cat((torch.cat((Br, -Bi), dim=3), torch.cat((Bi, Br), dim=3)), dim=2)\n",
        "            c_th = torch.matmul(a_th, b_th)\n",
        "            c_th_r = c_th[:, :, :, 0:int(c_th.shape[3] / 2), 0:int(c_th.shape[4] / 2)]\n",
        "            c_th_i = c_th[:, :, :, int(c_th.shape[3] / 2):, 0:int(c_th.shape[4] / 2)]\n",
        "        elif Br.ndim == 5:\n",
        "            a_th = torch.cat((torch.cat((Ar, -Ai), dim=3), torch.cat((Ai, Ar), dim=3)), dim=2)\n",
        "            b_th = torch.cat((torch.cat((Br, -Bi), dim=4), torch.cat((Bi, Br), dim=4)), dim=3)\n",
        "            c_th = torch.matmul(a_th, b_th)\n",
        "            c_th_r = c_th[:, :, :, 0:int(c_th.shape[3] / 2), 0:int(c_th.shape[4] / 2)]\n",
        "            c_th_i = c_th[:, :, :, int(c_th.shape[3] / 2):, 0:int(c_th.shape[4] / 2)]\n",
        "    else:\n",
        "        raise Exception('the dimension is not defined for Th_comp_matmul.')\n",
        "\n",
        "    return c_th_r, c_th_i\n",
        "\n",
        "def Th_inv(Ar, Ai):  # Complex inverse pytorch function ########\n",
        "    Ar_inv = torch.inverse(Ar + torch.matmul(torch.matmul(Ai, torch.inverse(Ar)), Ai))\n",
        "    Ai_inv = - torch.matmul(torch.matmul(torch.inverse(Ar), Ai), Ar_inv)\n",
        "    return Ar_inv, Ai_inv\n",
        "\n",
        "def Th_pinv(Ar, Ai):  # Complex inverse pytorch function ########\n",
        "    if Ar.ndim == 2:\n",
        "        if Ar.shape[0] < Ar.shape[1]:\n",
        "            Tempr, Tempi = Th_comp_matmul(Ar, Ai, Ar.T, -Ai.T)\n",
        "            Ar_inv, Ai_inv = Th_inv(Tempr, Tempi)\n",
        "            return Th_comp_matmul(Ar.T, -Ai.T, Ar_inv, Ai_inv)\n",
        "        elif Ar.shape[0] > Ar.shape[1]:\n",
        "            Tempr, Tempi = Th_comp_matmul(Ar.T, -Ai.T, Ar, Ai)\n",
        "            Ar_inv, Ai_inv = Th_inv(Tempr, Tempi)\n",
        "            return Th_comp_matmul(Ar_inv, Ai_inv, Ar.T, -Ai.T)\n",
        "        elif Ar.shape[0] == Ar.shape[1]:\n",
        "            return Th_inv(Ar, Ai)\n",
        "    elif Ar.ndim == 3:\n",
        "        if Ar.shape[1] < Ar.shape[2]:\n",
        "            Tempr, Tempi = Th_comp_matmul(Ar, Ai, Ar.permute(0, 2, 1), -Ai.permute(0, 2, 1))\n",
        "            Ar_inv, Ai_inv = Th_inv(Tempr, Tempi)\n",
        "            return Th_comp_matmul(Ar.permute(0, 2, 1), -Ai.permute(0, 2, 1), Ar_inv, Ai_inv)\n",
        "        elif Ar.shape[1] > Ar.shape[2]:\n",
        "            Tempr, Tempi = Th_comp_matmul(Ar.permute(0, 2, 1), -Ai.permute(0, 2, 1), Ar, Ai)\n",
        "            Ar_inv, Ai_inv = Th_inv(Tempr, Tempi)\n",
        "            return Th_comp_matmul(Ar_inv, Ai_inv, Ar.permute(0, 2, 1), -Ai.permute(0, 2, 1))\n",
        "        elif Ar.shape[1] == Ar.shape[2]:\n",
        "            return Th_inv(Ar, Ai)\n",
        "    elif Ar.ndim == 4:\n",
        "        if Ar.shape[2] < Ar.shape[3]:\n",
        "            Tempr, Tempi = Th_comp_matmul(Ar, Ai, Ar.permute(0, 1, 3, 2), -Ai.permute(0, 1, 3, 2))\n",
        "            Ar_inv, Ai_inv = Th_inv(Tempr, Tempi)\n",
        "            return Th_comp_matmul(Ar.permute(0, 1, 3, 2), -Ai.permute(0, 1, 3, 2), Ar_inv, Ai_inv)\n",
        "        elif Ar.shape[2] > Ar.shape[3]:\n",
        "            Tempr, Tempi = Th_comp_matmul(Ar.permute(0, 1, 3, 2), -Ai.permute(0, 1, 3, 2), Ar, Ai)\n",
        "            Ar_inv, Ai_inv = Th_inv(Tempr, Tempi)\n",
        "            return Th_comp_matmul(Ar_inv, Ai_inv, Ar.permute(0, 1, 3, 2), -Ai.permute(0, 1, 3, 2))\n",
        "        elif Ar.shape[2] == Ar.shape[3]:\n",
        "            return Th_inv(Ar, Ai)\n",
        "    else:\n",
        "        raise Exception('5-D is not defined for Th_pinv.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "from termcolor import colored\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from numpy import genfromtxt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import re\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "# Database ####################################################################################################################\n",
        "class Data_Reader(data.Dataset):\n",
        "    def __init__(self, filename, Us, Mr, Nrf, K):\n",
        "\n",
        "        print(colored('You select core dataset', 'cyan'))\n",
        "        print(colored(filename, 'yellow'), 'is loading ... ')\n",
        "        np_data = np.load(filename)\n",
        "\n",
        "        self.channelR = np_data[:, 0:Us * Mr].real.astype(float)\n",
        "        self.channelI = np_data[:, 0:Us * Mr].imag.astype(float)\n",
        "\n",
        "        self.alpha = np_data[:, Us * Mr: (Us * Mr) + (Us * K)].real.astype(float)\n",
        "\n",
        "        self.RSSI_N = np_data[:, (Us * Mr) + (Us * K):(Us * Mr) + (2 * Us * K)].real.astype(float)\n",
        "\n",
        "        self.UR = np_data[:, (Us * Mr) + (2 * Us * K):(2 * Us * Mr) + \n",
        "                          (2 * Us * K)].real.astype(float)\n",
        "        self.UI = np_data[:, (Us * Mr) + (2 * Us * K):(2 * Us * Mr) + \n",
        "                          (2 * Us * K)].imag.astype(float)\n",
        "\n",
        "        self.AR = np_data[:, Us * (2 * Mr + 2 * K):Us * (2 * Mr + 2 * K) + \n",
        "                          (Nrf * Mr)].real.astype(float)\n",
        "        self.AI = np_data[:, Us * (2 * Mr + 2 * K):Us * (2 * Mr + 2 * K) + \n",
        "                          (Nrf * Mr)].imag.astype(float)\n",
        "\n",
        "        self.target = np_data[:, Us * (2 * Mr + 2 * K) + (Nrf * Mr):Us * (2 * Mr + 2 * K) + \n",
        "                              (Nrf * Mr) + 1].real.astype(int)\n",
        "\n",
        "        self.WR = np_data[:, Us * (2 * Mr + 2 * K) + (Nrf * Mr) + 1:Us * \n",
        "                          (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1].real.astype(float)\n",
        "        self.WI = np_data[:, Us * (2 * Mr + 2 * K) + (Nrf * Mr) + 1:Us * \n",
        "                          (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1].imag.astype(float)\n",
        "\n",
        "        self.deltaR = np_data[:, Us * (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1:Us * \n",
        "                              (2 * Mr + 3 * K + Nrf) + (Nrf * Mr) + 1].real.astype(float)\n",
        "        self.deltaI = np_data[:, Us * (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1:Us * \n",
        "                              (2 * Mr + 3 * K + Nrf) + (Nrf * Mr) + 1].imag.astype(float)\n",
        "\n",
        "        self.userp = np_data[:, Us * (2 * Mr + 3 * K + Nrf) + (Nrf * Mr) + 1: Us * \n",
        "                             (2 * Mr + 3 * K + Nrf + 2) + (Nrf * Mr) + 1].real.astype(float)\n",
        "\n",
        "        self.n_samples = np_data.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def uniq_clas(self):\n",
        "        uniq = np.unique(self.target, return_counts=True)\n",
        "        NO_Class = np.unique(self.target).shape[0]\n",
        "        print(colored(\"The number of Unique AP in I1: \", \"green\"), NO_Class)\n",
        "        return np.max(uniq[1]) * 100 / uniq[1].sum()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return torch.Tensor(self.channelR[index]), torch.Tensor(self.channelI[index]), torch.Tensor(self.alpha[index]), \\\n",
        "            torch.Tensor(self.RSSI_N[index]), torch.Tensor(self.UR[index]), torch.Tensor(self.UI[index]), torch.Tensor(self.AR[index]), \\\n",
        "                torch.Tensor(self.AI[index]), torch.LongTensor(self.target[index]), torch.Tensor(self.WR[index]), torch.Tensor(self.WI[index]), \\\n",
        "                    torch.Tensor(self.deltaR[index]), torch.Tensor(self.deltaI[index]), torch.Tensor(self.userp[index])\n",
        "\n",
        "# readme reader for HBF initial parameters ####################################################################################\n",
        "def md_reader(DB_name):\n",
        "    md = genfromtxt('DATASET.md', delimiter='\\n', dtype='str')\n",
        "    Us = int(re.findall(r'\\d+', md[1])[0])\n",
        "    Mr = int(re.findall(r'\\d+', md[2])[0])\n",
        "    Nrf = int(re.findall(r'\\d+', md[3])[0])\n",
        "    Ass_n = int(re.findall(r'\\d+', md[4])[0])\n",
        "    Noise_pwr = float(''.join(('1e-', str(int(int(re.findall(r'\\d+', md[6])[0]) / 10)))))\n",
        "    return Us, Mr, Nrf, Ass_n, Noise_pwr\n",
        "\n",
        "class Initialization_Model_Params(object):\n",
        "    def __init__(self,\n",
        "                 DB_name,\n",
        "                 Us,\n",
        "                 Mr,\n",
        "                 Nrf,\n",
        "                 K,\n",
        "                 K_limited,\n",
        "                 Noise_pwr,\n",
        "                 device,\n",
        "                 device_ids\n",
        "                 ):\n",
        "        self.DB_name = DB_name\n",
        "        self.Us = Us\n",
        "        self.Mr = Mr\n",
        "        self.Nrf = Nrf\n",
        "        self.K = K\n",
        "        self.K_limited = K_limited\n",
        "        self.Noise_pwr = Noise_pwr\n",
        "        self.device = device\n",
        "        self.dev_id = device_ids\n",
        "\n",
        "    def Data_Load(self):\n",
        "        DataBase = Data_Reader(''.join(('DataBase_', self.DB_name, '.npy')),\n",
        "                               self.Us, self.Mr, self.Nrf, self.K)\n",
        "        uniq_dis_label = DataBase.uniq_clas()\n",
        "        return DataBase, uniq_dis_label\n",
        "\n",
        "    def Code_Read(self):\n",
        "        codes = genfromtxt('/content/drive/MyDrive/HBF-Net-main/Codebook/Codebook_ij.csv', delimiter=',', dtype='complex', skip_header=0)\n",
        "        label = np.arange(len(codes))\n",
        "        self.n_output_clas = len(codes)\n",
        "        print(colored(\"The length of the codebook: \", \"green\"), len(codes))\n",
        "        Codes_idx = np.concatenate((label[:, np.newaxis], codes), axis=1)\n",
        "        codeword_C = {}\n",
        "        index_C = []\n",
        "        for i in range(len(codes)):\n",
        "            index_C = Codes_idx[i, 0].real.astype(int)\n",
        "            icode_C = Codes_idx[i, 1:]\n",
        "            codeword_C[index_C] = icode_C\n",
        "\n",
        "        # torch tensor of codes\n",
        "        codesr = torch.from_numpy(codes.real).type(torch.float)\n",
        "        codesi = torch.from_numpy(codes.imag).type(torch.float)\n",
        "        return codeword_C, len(codes), codesr, codesi\n",
        "\n",
        "class Loss_FDP_Rate_Based(torch.nn.Module):\n",
        "    def __init__(self, Us, Mr, Nrf, Noise_pwr):\n",
        "        super(Loss_FDP_Rate_Based, self).__init__()\n",
        "        self.Us = Us\n",
        "        self.Mr = Mr\n",
        "        self.Nrf = Nrf\n",
        "        self.noise_power = Noise_pwr\n",
        "\n",
        "    def rate_calculator(self, u_re, u_im, channelr, channeli):\n",
        "        Wr, Wi = Th_comp_matmul(channelr, -channeli, u_re, u_im)\n",
        "        W = Wr**2 + Wi**2\n",
        "        diag_W = torch.diagonal(W, dim1=1, dim2=2)\n",
        "\n",
        "        SINR = diag_W / (torch.sum(W, 2) - diag_W + self.noise_power)\n",
        "        userRates = torch.log2(1 + SINR)\n",
        "        sumRate = userRates.sum(1)\n",
        "\n",
        "        return sumRate\n",
        "\n",
        "    def forward(self, outr, outi, channelr, channeli):\n",
        "        outr = outr.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "        outi = outi.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(outr.flatten(1) ** 2 + outi.flatten(1) ** 2, dim=1))\n",
        "        outr = (outr.flatten(1) / temp_pre.unsqueeze(1)).view(outr.shape)\n",
        "        outi = (outi.flatten(1) / temp_pre.unsqueeze(1)).view(outi.shape)\n",
        "\n",
        "        sum_rate = Loss_FDP_Rate_Based.rate_calculator(self, outr, outi, channelr, channeli)\n",
        "        return -sum_rate.mean()\n",
        "\n",
        "    def evaluate_rate(self, outr, outi, channelr, channeli):\n",
        "        outr = outr.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "        outi = outi.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(outr.flatten(1) ** 2 + outi.flatten(1) ** 2, dim=1))\n",
        "        outr = (outr.flatten(1) / temp_pre.unsqueeze(1)).view(outr.shape)\n",
        "        outi = (outi.flatten(1) / temp_pre.unsqueeze(1)).view(outi.shape)\n",
        "\n",
        "        sum_rate = Loss_FDP_Rate_Based.rate_calculator(self, outr, outi, channelr, channeli)\n",
        "        return sum_rate.mean()\n",
        "\n",
        "class Loss_HBF_Rate_Based_4D(torch.nn.Module):\n",
        "    def __init__(self, Us, Mr, Nrf, Noise_pwr):\n",
        "        super(Loss_HBF_Rate_Based_4D, self).__init__()\n",
        "        self.Us = Us\n",
        "        self.Mr = Mr\n",
        "        self.Nrf = Nrf\n",
        "        self.noise_power = Noise_pwr\n",
        "\n",
        "    def rate_calculator_4d(self, u_re, u_im, channelr, channeli):\n",
        "        Wr, Wi = Th_comp_matmul(channelr, -channeli, u_re, u_im)\n",
        "        W = Wr**2 + Wi**2\n",
        "        diag_W = torch.diagonal(W, dim1=2, dim2=3)\n",
        "        SINR = diag_W / (torch.sum(W, 3) - diag_W + self.noise_power)\n",
        "        userRates = torch.log2(1 + SINR)\n",
        "        sumRate = userRates.sum(2)\n",
        "        return sumRate\n",
        "\n",
        "    def forward(self, Wr, Wi, channelr, channeli, Ar, Ai):\n",
        "        HBF_prer, HBF_prei = Th_comp_matmul(Ar.view(-1, len(channelr), self.Nrf, self.Mr).permute(0, 1, 3, 2),\n",
        "                                            Ai.view(-1, len(channelr), self.Nrf, self.Mr).permute(0, 1, 3, 2), Wr, Wi)\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(HBF_prer.flatten(2) ** 2 + HBF_prei.flatten(2) ** 2, dim=2))\n",
        "        HBF_prer = (HBF_prer.flatten(2) / temp_pre.unsqueeze(2)).view(HBF_prer.shape)\n",
        "        HBF_prei = (HBF_prei.flatten(2) / temp_pre.unsqueeze(2)).view(HBF_prei.shape)\n",
        "\n",
        "        sum_rate = Loss_HBF_Rate_Based_4D.rate_calculator_4d(self, HBF_prer, HBF_prei, channelr, channeli)\n",
        "        return sum_rate.T\n",
        "\n",
        "    def evaluate_rate(self, Wr, Wi, channelr, channeli, Ar, Ai):\n",
        "        HBF_prer, HBF_prei = Th_comp_matmul(Ar.view(-1, self.Nrf, self.Mr).permute(0, 2, 1),\n",
        "            Ai.view(-1, self.Nrf, self.Mr).permute(0, 2, 1), Wr.permute(0, 2, 1), Wi.permute(0, 2, 1))\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(HBF_prer.flatten(1) ** 2 + HBF_prei.flatten(1) ** 2, dim=1))\n",
        "        HBF_prer = (HBF_prer.flatten(1) / temp_pre.unsqueeze(1)).view(HBF_prer.shape)\n",
        "        HBF_prei = (HBF_prei.flatten(1) / temp_pre.unsqueeze(1)).view(HBF_prei.shape)\n",
        "\n",
        "        sum_rate = Loss_FDP_Rate_Based.rate_calculator(self, HBF_prer, HBF_prei, channelr, channeli)\n",
        "\n",
        "        return sum_rate.mean()\n",
        "\n",
        "def FLP_loss(x, y):\n",
        "    log_prob = - 1.0 * F.softmax(x, 1)\n",
        "    temp = log_prob * y\n",
        "    cel = temp.sum(dim=1)\n",
        "    cel = cel.mean()\n",
        "    return cel\n"
      ],
      "metadata": {
        "id": "qh9ZYMICvYa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-0GEXsAcTzd"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data\n",
        "from termcolor import colored\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from numpy import genfromtxt\n",
        "import numpy as np\n",
        "import re\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "# Database ####################################################################################################################\n",
        "class Data_Reader(data.Dataset):\n",
        "    def __init__(self, filename, Us, Mr, Nrf, K):\n",
        "\n",
        "        print(colored('You select core dataset', 'cyan'))\n",
        "        print(colored(filename, 'yellow'), 'is loading ... ')\n",
        "        np_data1 = np.load(filename)\n",
        "        #m6\n",
        "        file3=np.load('/content/drive/MyDrive/HBF-Net-main/pcaorpca.npy')\n",
        "        #a4=np.abs(file3)\n",
        "        #a5=np.max(a4)\n",
        "        #a6=np.min(a4)\n",
        "        #a7=(a4-a6)/(a5-a6)\n",
        "        sc = StandardScaler()\n",
        "      \n",
        "        \n",
        "        pca1 = PCA(n_components = 128)\n",
        "  \n",
        "        \n",
        "        RSSI_N1= np_data1[:, (Us * Mr) + (Us * K):(Us * Mr) + (2 * Us * K)].real.astype(float)\n",
        "        X_train1 = sc.fit_transform(RSSI_N1)\n",
        "        np_data2 = pca1.fit_transform(X_train1)\n",
        "        #end\n",
        "        pca2 = PCA(n_components = 256)        \n",
        "        channelR1 = np_data1[:, 0:Us * Mr].real.astype(float)\n",
        "        X_train2 = sc.fit_transform(channelR1)\n",
        "        np_data3 = pca2.fit_transform(X_train2)\n",
        "\n",
        "\n",
        "\n",
        "        #self.channelR = np_data1[:, 0:Us * Mr].real.astype(float)\n",
        "        self.channelR = np_data3\n",
        "        channelI1 = np_data1[:, 0:Us * Mr].imag.astype(float)   \n",
        "        pca3 = PCA(n_components = 256)        \n",
        "        #channelR1 = np_data1[:, 0:Us * Mr].real.astype(float)\n",
        "        X_train3 = sc.fit_transform(channelI1)\n",
        "        np_data4 = pca3.fit_transform(X_train3)             \n",
        "        #self.channelI = np_data1[:, 0:Us * Mr].imag.astype(float)\n",
        "        self.channelI = np_data4\n",
        "        alpha1 = np_data1[:, Us * Mr: (Us * Mr) + (Us * K)].real.astype(float)\n",
        "        pcap = PCA(n_components = 128)        \n",
        "        #channelR1 = np_data1[:, 0:Us * Mr].real.astype(float)\n",
        "        X_trainp = sc.fit_transform(alpha1)\n",
        "        np_datap = pcap.fit_transform(X_trainp)   \n",
        "\n",
        "\n",
        "        self.alpha = np_datap\n",
        "\n",
        "        #self.RSSI_N = np_data2[:, (Us * Mr) + (Us * K):(Us * Mr) + (2 * Us * K)].real.astype(float)\n",
        "        self.RSSI_N = np_data2\n",
        "        UR1 = np_data1[:, (Us * Mr) + (2 * Us * K):(2 * Us * Mr) + \n",
        "                          (2 * Us * K)].real.astype(float)\n",
        "        pca5 = PCA(n_components = 256)        \n",
        "        #channelR1 = np_data1[:, 0:Us * Mr].real.astype(float)\n",
        "        X_train4 = sc.fit_transform(UR1)\n",
        "        np_data5 = pca5.fit_transform(X_train4)   \n",
        "        self.UR = np_data5\n",
        "        #self.UR = np_data1[:, (Us * Mr) + (2 * Us * K):(2 * Us * Mr) + \n",
        "                          #(2 * Us * K)].real.astype(float)\n",
        "        UI1 = np_data1[:, (Us * Mr) + (2 * Us * K):(2 * Us * Mr) + \n",
        "                          (2 * Us * K)].imag.astype(float)\n",
        "        pca6 = PCA(n_components = 256)        \n",
        "        #channelR1 = np_data1[:, 0:Us * Mr].real.astype(float)\n",
        "        X_train5 = sc.fit_transform(UI1)\n",
        "        np_data6 = pca6.fit_transform(X_train5)  \n",
        "\n",
        "        self.UI= np_data6\n",
        "\n",
        "\n",
        "        #self.UI = np_data1[:, (Us * Mr) + (2 * Us * K):(2 * Us * Mr) + \n",
        "                          #(2 * Us * K)].imag.astype(float)\n",
        "\n",
        "        AR1 = np_data1[:, Us * (2 * Mr + 2 * K):Us * (2 * Mr + 2 * K) + \n",
        "                          (Nrf * Mr)].real.astype(float)\n",
        "        pca7 = PCA(n_components = 512)        \n",
        "        #channelR1 = np_data1[:, 0:Us * Mr].real.astype(float)\n",
        "        X_train6 = sc.fit_transform(AR1)\n",
        "        np_data7 = pca7.fit_transform(X_train6)  \n",
        "        self.AR = np_data7\n",
        "        AI1 = np_data1[:, Us * (2 * Mr + 2 * K):Us * (2 * Mr + 2 * K) + \n",
        "                          (Nrf * Mr)].imag.astype(float)\n",
        "        X_train7 = sc.fit_transform(AI1)\n",
        "        np_data8 = pca7.fit_transform(X_train7)  \n",
        "        self.AI = np_data8\n",
        "        target1 = np_data1[:, Us * (2 * Mr + 2 * K) + (Nrf * Mr):Us * (2 * Mr + 2 * K) + \n",
        "                              (Nrf * Mr) + 1].real.astype(int)\n",
        "        pca8 = PCA(n_components = 1)\n",
        "        X_train8 = sc.fit_transform(target1)\n",
        "        np_data9 = pca8.fit_transform(X_train8)  \n",
        "\n",
        "\n",
        "        self.target = np_data9\n",
        "        WR1 = np_data1[:, Us * (2 * Mr + 2 * K) + (Nrf * Mr) + 1:Us * \n",
        "                          (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1].real.astype(float)\n",
        "        X_train9 = sc.fit_transform(WR1)\n",
        "        pca9 = PCA(n_components = 32)\n",
        "        np_data10 = pca9.fit_transform(X_train9)  \n",
        "\n",
        "       \n",
        "        self.WR = np_data10\n",
        "        WI1 = np_data1[:, Us * (2 * Mr + 2 * K) + (Nrf * Mr) + 1:Us * \n",
        "                          (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1].imag.astype(float)\n",
        "        X_train10 = sc.fit_transform(WI1)\n",
        "        np_data11 = pca9.fit_transform(X_train10)  \n",
        "\n",
        "        self.WI = np_data11\n",
        "        deltaR1 = np_data1[:, Us * (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1:Us * \n",
        "                              (2 * Mr + 3 * K + Nrf) + (Nrf * Mr) + 1].real.astype(float)\n",
        "        X_train11= sc.fit_transform(deltaR1)\n",
        "        pca10 = PCA(n_components = 128)\n",
        "        np_data12 = pca10.fit_transform(X_train11)  \n",
        "         \n",
        "        self.deltaR = np_data12\n",
        "\n",
        "        deltaI1 = np_data1[:, Us * (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1:Us * \n",
        "                              (2 * Mr + 3 * K + Nrf) + (Nrf * Mr) + 1].imag.astype(float)\n",
        "        X_train12= sc.fit_transform(deltaI1)\n",
        "        np_data13 = pca10.fit_transform(X_train12) \n",
        "\n",
        "        self.deltaI = np_data13\n",
        "        pca11 = PCA(n_components = 8) \n",
        "        userp1 = np_data1[:, Us * (2 * Mr + 3 * K + Nrf) + (Nrf * Mr) + 1: Us * \n",
        "                             (2 * Mr + 3 * K + Nrf + 2) + (Nrf * Mr) + 1].real.astype(float)\n",
        "        X_train13= sc.fit_transform(userp1)\n",
        "        np_data14 = pca11.fit_transform(X_train13) \n",
        "        \n",
        "        self.userp = np_data14\n",
        "\n",
        "        self.n_samples =np_data1.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def uniq_clas(self):\n",
        "        uniq = np.unique(self.target, return_counts=True)\n",
        "        NO_Class = np.unique(self.target).shape[0]\n",
        "        print(colored(\"The number of Unique AP in I1: \", \"green\"), NO_Class)\n",
        "        return np.max(uniq[1]) * 100 / uniq[1].sum()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return torch.Tensor(self.channelR[index]), torch.Tensor(self.channelI[index]), torch.Tensor(self.alpha[index]), \\\n",
        "            torch.Tensor(self.RSSI_N[index]), torch.Tensor(self.UR[index]), torch.Tensor(self.UI[index]), torch.Tensor(self.AR[index]), \\\n",
        "                torch.Tensor(self.AI[index]), torch.LongTensor(self.target[index]), torch.Tensor(self.WR[index]), torch.Tensor(self.WI[index]), \\\n",
        "                    torch.Tensor(self.deltaR[index]), torch.Tensor(self.deltaI[index]), torch.Tensor(self.userp[index])\n",
        "\n",
        "# readme reader for HBF initial parameters ####################################################################################\n",
        "def md_reader(DB_name):\n",
        "    md = genfromtxt('DATASET.md', delimiter='\\n', dtype='str')\n",
        "    #md = genfromtxt('newdataset1.md', delimiter='\\n', dtype='str')\n",
        "    Us = int(re.findall(r'\\d+', md[1])[0])\n",
        "    Mr = int(re.findall(r'\\d+', md[2])[0])\n",
        "    Nrf = int(re.findall(r'\\d+', md[3])[0])\n",
        "    Ass_n = int(re.findall(r'\\d+', md[4])[0])\n",
        "    Noise_pwr = float(''.join(('1e-', str(int(int(re.findall(r'\\d+', md[6])[0]) / 10)))))\n",
        "    return Us, Mr, Nrf, Ass_n, Noise_pwr\n",
        "\n",
        "class Initialization_Model_Params(object):\n",
        "    def __init__(self,\n",
        "                 DB_name,\n",
        "                 Us,\n",
        "                 Mr,\n",
        "                 Nrf,\n",
        "                 K,\n",
        "                 K_limited,\n",
        "                 Noise_pwr,\n",
        "                 device,\n",
        "                 device_ids\n",
        "                 ):\n",
        "        self.DB_name = DB_name\n",
        "        self.Us = Us\n",
        "        self.Mr = Mr\n",
        "        self.Nrf = Nrf\n",
        "        self.K = K\n",
        "        self.K_limited = K_limited\n",
        "        self.Noise_pwr = Noise_pwr\n",
        "        self.device = device\n",
        "        self.dev_id = device_ids\n",
        "\n",
        "    def Data_Load(self):\n",
        "        #DataBase = Data_Reader(''.join(('DataBase_', self.DB_name, '.npy')),\n",
        "        DataBase = Data_Reader(''.join(('DataBase_', self.DB_name, '.npy')),\n",
        "        #DataBase = Data_Reader('/content/drive/MyDrive/HBF-Net-main/raw32_2p4.npy', \n",
        "                               self.Us, self.Mr, self.Nrf, self.K)\n",
        "        uniq_dis_label = DataBase.uniq_clas()\n",
        "        return DataBase, uniq_dis_label\n",
        "\n",
        "    def Code_Read(self):\n",
        "        #codes = genfromtxt('Codebook_ij.csv', delimiter=',', dtype='complex', skip_header=0)\n",
        "        codes = genfromtxt('/content/drive/MyDrive/HBF-Net-main/Codebook/Codebook_ij.csv', delimiter=',', dtype='complex', skip_header=0)\n",
        "        #codes = genfromtxt('/content/drive/MyDrive/HBF-Net-main/Codebook/newexample2.csv', delimiter=',', dtype='complex', skip_header=0)\n",
        "        label = np.arange(len(codes))\n",
        "        self.n_output_clas = len(codes)\n",
        "        print(colored(\"The length of the codebook: \", \"green\"), len(codes))\n",
        "        Codes_idx = np.concatenate((label[:, np.newaxis], codes), axis=1)\n",
        "        codeword_C = {}\n",
        "        index_C = []\n",
        "        for i in range(len(codes)):\n",
        "            index_C = Codes_idx[i, 0].real.astype(int)\n",
        "            icode_C = Codes_idx[i, 1:]\n",
        "            codeword_C[index_C] = icode_C\n",
        "\n",
        "        # torch tensor of codes\n",
        "        codesr = torch.from_numpy(codes.real).type(torch.float)\n",
        "        codesi = torch.from_numpy(codes.imag).type(torch.float)\n",
        "        return codeword_C, len(codes), codesr, codesi\n",
        "\n",
        "class Loss_FDP_Rate_Based(torch.nn.Module):\n",
        "    def __init__(self, Us, Mr, Nrf, Noise_pwr):\n",
        "        super(Loss_FDP_Rate_Based, self).__init__()\n",
        "        self.Us = Us\n",
        "        self.Mr = Mr\n",
        "        self.Nrf = Nrf\n",
        "        self.noise_power = Noise_pwr\n",
        "\n",
        "    def rate_calculator(self, u_re, u_im, channelr, channeli):\n",
        "        Wr, Wi = Th_comp_matmul(channelr, -channeli, u_re, u_im)\n",
        "        W = Wr**2 + Wi**2\n",
        "        diag_W = torch.diagonal(W, dim1=1, dim2=2)\n",
        "\n",
        "        SINR = diag_W / (torch.sum(W, 2) - diag_W + self.noise_power)\n",
        "        userRates = torch.log2(1 + SINR)\n",
        "        sumRate = userRates.sum(1)\n",
        "\n",
        "        return sumRate\n",
        "\n",
        "    def forward(self, outr, outi, channelr, channeli):\n",
        "        outr = outr.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "        outi = outi.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(outr.flatten(1) ** 2 + outi.flatten(1) ** 2, dim=1))\n",
        "        outr = (outr.flatten(1) / temp_pre.unsqueeze(1)).view(outr.shape)\n",
        "        outi = (outi.flatten(1) / temp_pre.unsqueeze(1)).view(outi.shape)\n",
        "\n",
        "        sum_rate = Loss_FDP_Rate_Based.rate_calculator(self, outr, outi, channelr, channeli)\n",
        "        return -sum_rate.mean()\n",
        "\n",
        "    def evaluate_rate(self, outr, outi, channelr, channeli):\n",
        "        outr = outr.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "        outi = outi.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(outr.flatten(1) ** 2 + outi.flatten(1) ** 2, dim=1))\n",
        "        outr = (outr.flatten(1) / temp_pre.unsqueeze(1)).view(outr.shape)\n",
        "        outi = (outi.flatten(1) / temp_pre.unsqueeze(1)).view(outi.shape)\n",
        "\n",
        "        sum_rate = Loss_FDP_Rate_Based.rate_calculator(self, outr, outi, channelr, channeli)\n",
        "        return sum_rate.mean()\n",
        "\n",
        "class Loss_HBF_Rate_Based_4D(torch.nn.Module):\n",
        "    def __init__(self, Us, Mr, Nrf, Noise_pwr):\n",
        "        super(Loss_HBF_Rate_Based_4D, self).__init__()\n",
        "        self.Us = Us\n",
        "        self.Mr = Mr\n",
        "        self.Nrf = Nrf\n",
        "        self.noise_power = Noise_pwr\n",
        "\n",
        "    def rate_calculator_4d(self, u_re, u_im, channelr, channeli):\n",
        "        Wr, Wi = Th_comp_matmul(channelr, -channeli, u_re, u_im)\n",
        "        W = Wr**2 + Wi**2\n",
        "        diag_W = torch.diagonal(W, dim1=2, dim2=3)\n",
        "        SINR = diag_W / (torch.sum(W, 3) - diag_W + self.noise_power)\n",
        "        userRates = torch.log2(1 + SINR)\n",
        "        sumRate = userRates.sum(2)\n",
        "        return sumRate\n",
        "\n",
        "    def forward(self, Wr, Wi, channelr, channeli, Ar, Ai):\n",
        "        HBF_prer, HBF_prei = Th_comp_matmul(Ar.view(-1, len(channelr), self.Nrf, self.Mr).permute(0, 1, 3, 2),\n",
        "                                            Ai.view(-1, len(channelr), self.Nrf, self.Mr).permute(0, 1, 3, 2), Wr, Wi)\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(HBF_prer.flatten(2) ** 2 + HBF_prei.flatten(2) ** 2, dim=2))\n",
        "        HBF_prer = (HBF_prer.flatten(2) / temp_pre.unsqueeze(2)).view(HBF_prer.shape)\n",
        "        HBF_prei = (HBF_prei.flatten(2) / temp_pre.unsqueeze(2)).view(HBF_prei.shape)\n",
        "\n",
        "        sum_rate = Loss_HBF_Rate_Based_4D.rate_calculator_4d(self, HBF_prer, HBF_prei, channelr, channeli)\n",
        "        return sum_rate.T\n",
        "\n",
        "    def evaluate_rate(self, Wr, Wi, channelr, channeli, Ar, Ai):\n",
        "        HBF_prer, HBF_prei = Th_comp_matmul(Ar.view(-1, self.Nrf, self.Mr).permute(0, 2, 1),\n",
        "            Ai.view(-1, self.Nrf, self.Mr).permute(0, 2, 1), Wr.permute(0, 2, 1), Wi.permute(0, 2, 1))\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(HBF_prer.flatten(1) ** 2 + HBF_prei.flatten(1) ** 2, dim=1))\n",
        "        HBF_prer = (HBF_prer.flatten(1) / temp_pre.unsqueeze(1)).view(HBF_prer.shape)\n",
        "        HBF_prei = (HBF_prei.flatten(1) / temp_pre.unsqueeze(1)).view(HBF_prei.shape)\n",
        "\n",
        "        sum_rate = Loss_FDP_Rate_Based.rate_calculator(self, HBF_prer, HBF_prei, channelr, channeli)\n",
        "\n",
        "        return sum_rate.mean()\n",
        "\n",
        "def FLP_loss(x, y):\n",
        "    #log_prob = - 1.0 * F.softmax(x, 1)\n",
        "    #log_prob =  1.0 * F.log_softmax(x,1)\n",
        "    log_prob = - 1.0 * F.softmax(x, 1)\n",
        "    temp = log_prob * y\n",
        "    cel = temp.sum(dim=1)\n",
        "    cel = cel.mean()\n",
        "    return cel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ssl import CHANNEL_BINDING_TYPES\n",
        "import torch.utils.data as data\n",
        "from termcolor import colored\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from numpy import genfromtxt\n",
        "import numpy as np\n",
        "import re\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import sparse\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "from sklearn.decomposition import FastICA\n",
        "# Database ####################################################################################################################\n",
        "class Data_Reader(data.Dataset):\n",
        "    def __init__(self, filename, Us, Mr, Nrf, K):\n",
        "\n",
        "        print(colored('You select core dataset', 'cyan'))\n",
        "        print(colored(filename, 'yellow'), 'is loading ... ')\n",
        "        np_data = np.load(filename)\n",
        "        transformer = IncrementalPCA(n_components=128, batch_size=500)\n",
        "\n",
        "\n",
        "\n",
        "        #pca = PCA(n_components=128, svd_solver='full')\n",
        "        #pca = PCA(n_components=1, svd_solver='arpack')\n",
        "        \n",
        "        RSSI_N1 = np_data[:, (Us * Mr) + (Us * K):(Us * Mr) + (2 * Us * K)].real.astype(float)\n",
        "        #np_data2= pca.fit_transform(RSSI_N1)\n",
        "        X_sparse = sparse.csr_matrix(RSSI_N1)\n",
        "        np_data2 = transformer.fit_transform(X_sparse)\n",
        "        #transformer = SparsePCA(n_components=128, random_state=0)\n",
        "        #transformer = KernelPCA(n_components=128, kernel='linear')\n",
        "        #np_data2 = transformer.fit_transform(RSSI_N1)\n",
        "        #model = NMF(n_components=128, init='random', random_state=0)\n",
        "        #np_data2 = model.fit_transform(RSSI_N1)\n",
        "        #transformer = FactorAnalysis(n_components=128, random_state=0)\n",
        "        #X_transformed = transformer.fit_transform(RSSI_N1)\n",
        "        #transformer = FastICA(n_components=128,\n",
        "                              #random_state=0,\n",
        "                              #whiten='unit-variance')\n",
        "        #np_data2 = transformer.fit_transform(RSSI_N1)\n",
        "        #model = NMF(n_components=128, init='random', random_state=0)\n",
        "        #np_data3 = model.fit_transform(model)       \n",
        "        #transformer = KernelPCA(n_components=128, kernel='linear')\n",
        "        #np_data3 = transformer.fit_transform(np_data2)\n",
        "        #channelR = np_data[:, 0:Us * Mr].real.astype(float)\n",
        "        #transformer2 = IncrementalPCA(n_components=256, batch_size=500)\n",
        "        #X_sparse2 = sparse.csr_matrix(channelR)\n",
        "        #np_data3 = transformer2.fit_transform(X_sparse2)\n",
        "\n",
        "        self.channelR = np_data[:, 0:Us * Mr].real.astype(float)\n",
        "        #channelI = np_data[:, 0:Us * Mr].imag.astype(float)\n",
        "        #transformer3 = IncrementalPCA(n_components=256, batch_size=500)\n",
        "        #X_sparse3 = sparse.csr_matrix(channelI)\n",
        "        #np_data4 = transformer3.fit_transform(X_sparse3)\n",
        "        self.channelI = np_data[:, 0:Us * Mr].imag.astype(float)\n",
        "\n",
        "        self.alpha = np_data[:, Us * Mr: (Us * Mr) + (Us * K)].real.astype(float)\n",
        "\n",
        "       # self.RSSI_N = np_data[:, (Us * Mr) + (Us * K):(Us * Mr) + (2 * Us * K)].real.astype(float)\n",
        "        self.RSSI_N = np_data2\n",
        "        self.UR = np_data[:, (Us * Mr) + (2 * Us * K):(2 * Us * Mr) + \n",
        "                          (2 * Us * K)].real.astype(float)\n",
        "        self.UI = np_data[:, (Us * Mr) + (2 * Us * K):(2 * Us * Mr) + \n",
        "                          (2 * Us * K)].imag.astype(float)\n",
        "\n",
        "        self.AR = np_data[:, Us * (2 * Mr + 2 * K):Us * (2 * Mr + 2 * K) + \n",
        "                          (Nrf * Mr)].real.astype(float)\n",
        "        self.AI = np_data[:, Us * (2 * Mr + 2 * K):Us * (2 * Mr + 2 * K) + \n",
        "                          (Nrf * Mr)].imag.astype(float)\n",
        "\n",
        "        self.target = np_data[:, Us * (2 * Mr + 2 * K) + (Nrf * Mr):Us * (2 * Mr + 2 * K) + \n",
        "                              (Nrf * Mr) + 1].real.astype(int)\n",
        "\n",
        "        self.WR = np_data[:, Us * (2 * Mr + 2 * K) + (Nrf * Mr) + 1:Us * \n",
        "                          (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1].real.astype(float)\n",
        "        self.WI = np_data[:, Us * (2 * Mr + 2 * K) + (Nrf * Mr) + 1:Us * \n",
        "                          (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1].imag.astype(float)\n",
        "\n",
        "        self.deltaR = np_data[:, Us * (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1:Us * \n",
        "                              (2 * Mr + 3 * K + Nrf) + (Nrf * Mr) + 1].real.astype(float)\n",
        "        self.deltaI = np_data[:, Us * (2 * Mr + 2 * K + Nrf) + (Nrf * Mr) + 1:Us * \n",
        "                              (2 * Mr + 3 * K + Nrf) + (Nrf * Mr) + 1].imag.astype(float)\n",
        "\n",
        "        self.userp = np_data[:, Us * (2 * Mr + 3 * K + Nrf) + (Nrf * Mr) + 1: Us * \n",
        "                             (2 * Mr + 3 * K + Nrf + 2) + (Nrf * Mr) + 1].real.astype(float)\n",
        "\n",
        "        self.n_samples = np_data.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def uniq_clas(self):\n",
        "        uniq = np.unique(self.target, return_counts=True)\n",
        "        NO_Class = np.unique(self.target).shape[0]\n",
        "        print(colored(\"The number of Unique AP in I1: \", \"green\"), NO_Class)\n",
        "        return np.max(uniq[1]) * 100 / uniq[1].sum()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return torch.Tensor(self.channelR[index]), torch.Tensor(self.channelI[index]), torch.Tensor(self.alpha[index]), \\\n",
        "            torch.Tensor(self.RSSI_N[index]), torch.Tensor(self.UR[index]), torch.Tensor(self.UI[index]), torch.Tensor(self.AR[index]), \\\n",
        "                torch.Tensor(self.AI[index]), torch.LongTensor(self.target[index]), torch.Tensor(self.WR[index]), torch.Tensor(self.WI[index]), \\\n",
        "                    torch.Tensor(self.deltaR[index]), torch.Tensor(self.deltaI[index]), torch.Tensor(self.userp[index])\n",
        "\n",
        "# readme reader for HBF initial parameters ####################################################################################\n",
        "def md_reader(DB_name):\n",
        "    md = genfromtxt('DATASET.md', delimiter='\\n', dtype='str')\n",
        "    Us = int(re.findall(r'\\d+', md[1])[0])\n",
        "    Mr = int(re.findall(r'\\d+', md[2])[0])\n",
        "    Nrf = int(re.findall(r'\\d+', md[3])[0])\n",
        "    Ass_n = int(re.findall(r'\\d+', md[4])[0])\n",
        "    Noise_pwr = float(''.join(('1e-', str(int(int(re.findall(r'\\d+', md[6])[0]) / 10)))))\n",
        "    return Us, Mr, Nrf, Ass_n, Noise_pwr\n",
        "\n",
        "class Initialization_Model_Params(object):\n",
        "    def __init__(self,\n",
        "                 DB_name,\n",
        "                 Us,\n",
        "                 Mr,\n",
        "                 Nrf,\n",
        "                 K,\n",
        "                 K_limited,\n",
        "                 Noise_pwr,\n",
        "                 device,\n",
        "                 device_ids\n",
        "                 ):\n",
        "        self.DB_name = DB_name\n",
        "        self.Us = Us\n",
        "        self.Mr = Mr\n",
        "        self.Nrf = Nrf\n",
        "        self.K = K\n",
        "        self.K_limited = K_limited\n",
        "        self.Noise_pwr = Noise_pwr\n",
        "        self.device = device\n",
        "        self.dev_id = device_ids\n",
        "\n",
        "    def Data_Load(self):\n",
        "        DataBase = Data_Reader(''.join(('DataBase_', self.DB_name, '.npy')),\n",
        "                               self.Us, self.Mr, self.Nrf, self.K)\n",
        "        uniq_dis_label = DataBase.uniq_clas()\n",
        "        return DataBase, uniq_dis_label\n",
        "\n",
        "    def Code_Read(self):\n",
        "        codes = genfromtxt('/content/drive/MyDrive/HBF-Net-main/Codebook/Codebook_ij.csv', delimiter=',', dtype='complex', skip_header=0)\n",
        "        label = np.arange(len(codes))\n",
        "        self.n_output_clas = len(codes)\n",
        "        print(colored(\"The length of the codebook: \", \"green\"), len(codes))\n",
        "        Codes_idx = np.concatenate((label[:, np.newaxis], codes), axis=1)\n",
        "        codeword_C = {}\n",
        "        index_C = []\n",
        "        for i in range(len(codes)):\n",
        "            index_C = Codes_idx[i, 0].real.astype(int)\n",
        "            icode_C = Codes_idx[i, 1:]\n",
        "            codeword_C[index_C] = icode_C\n",
        "\n",
        "        # torch tensor of codes\n",
        "        codesr = torch.from_numpy(codes.real).type(torch.float)\n",
        "        codesi = torch.from_numpy(codes.imag).type(torch.float)\n",
        "        return codeword_C, len(codes), codesr, codesi\n",
        "\n",
        "class Loss_FDP_Rate_Based(torch.nn.Module):\n",
        "    def __init__(self, Us, Mr, Nrf, Noise_pwr):\n",
        "        super(Loss_FDP_Rate_Based, self).__init__()\n",
        "        self.Us = Us\n",
        "        self.Mr = Mr\n",
        "        self.Nrf = Nrf\n",
        "        self.noise_power = Noise_pwr\n",
        "\n",
        "    def rate_calculator(self, u_re, u_im, channelr, channeli):\n",
        "        Wr, Wi = Th_comp_matmul(channelr, -channeli, u_re, u_im)\n",
        "        W = Wr**2 + Wi**2\n",
        "        diag_W = torch.diagonal(W, dim1=1, dim2=2)\n",
        "\n",
        "        SINR = diag_W / (torch.sum(W, 2) - diag_W + self.noise_power)\n",
        "        userRates = torch.log2(1 + SINR)\n",
        "        sumRate = userRates.sum(1)\n",
        "\n",
        "        return sumRate\n",
        "\n",
        "    def forward(self, outr, outi, channelr, channeli):\n",
        "        outr = outr.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "        outi = outi.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(outr.flatten(1) ** 2 + outi.flatten(1) ** 2, dim=1))\n",
        "        outr = (outr.flatten(1) / temp_pre.unsqueeze(1)).view(outr.shape)\n",
        "        outi = (outi.flatten(1) / temp_pre.unsqueeze(1)).view(outi.shape)\n",
        "\n",
        "        sum_rate = Loss_FDP_Rate_Based.rate_calculator(self, outr, outi, channelr, channeli)\n",
        "        return -sum_rate.mean()\n",
        "\n",
        "    def evaluate_rate(self, outr, outi, channelr, channeli):\n",
        "        outr = outr.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "        outi = outi.view(-1, self.Us, self.Mr).permute(0, 2, 1)\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(outr.flatten(1) ** 2 + outi.flatten(1) ** 2, dim=1))\n",
        "        outr = (outr.flatten(1) / temp_pre.unsqueeze(1)).view(outr.shape)\n",
        "        outi = (outi.flatten(1) / temp_pre.unsqueeze(1)).view(outi.shape)\n",
        "\n",
        "        sum_rate = Loss_FDP_Rate_Based.rate_calculator(self, outr, outi, channelr, channeli)\n",
        "        return sum_rate.mean()\n",
        "\n",
        "class Loss_HBF_Rate_Based_4D(torch.nn.Module):\n",
        "    def __init__(self, Us, Mr, Nrf, Noise_pwr):\n",
        "        super(Loss_HBF_Rate_Based_4D, self).__init__()\n",
        "        self.Us = Us\n",
        "        self.Mr = Mr\n",
        "        self.Nrf = Nrf\n",
        "        self.noise_power = Noise_pwr\n",
        "\n",
        "    def rate_calculator_4d(self, u_re, u_im, channelr, channeli):\n",
        "        Wr, Wi = Th_comp_matmul(channelr, -channeli, u_re, u_im)\n",
        "        W = Wr**2 + Wi**2\n",
        "        diag_W = torch.diagonal(W, dim1=2, dim2=3)\n",
        "        SINR = diag_W / (torch.sum(W, 3) - diag_W + self.noise_power)\n",
        "        userRates = torch.log2(1 + SINR)\n",
        "        sumRate = userRates.sum(2)\n",
        "        return sumRate\n",
        "\n",
        "    def forward(self, Wr, Wi, channelr, channeli, Ar, Ai):\n",
        "        HBF_prer, HBF_prei = Th_comp_matmul(Ar.view(-1, len(channelr), self.Nrf, self.Mr).permute(0, 1, 3, 2),\n",
        "                                            Ai.view(-1, len(channelr), self.Nrf, self.Mr).permute(0, 1, 3, 2), Wr, Wi)\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(HBF_prer.flatten(2) ** 2 + HBF_prei.flatten(2) ** 2, dim=2))\n",
        "        HBF_prer = (HBF_prer.flatten(2) / temp_pre.unsqueeze(2)).view(HBF_prer.shape)\n",
        "        HBF_prei = (HBF_prei.flatten(2) / temp_pre.unsqueeze(2)).view(HBF_prei.shape)\n",
        "\n",
        "        sum_rate = Loss_HBF_Rate_Based_4D.rate_calculator_4d(self, HBF_prer, HBF_prei, channelr, channeli)\n",
        "        return sum_rate.T\n",
        "\n",
        "    def evaluate_rate(self, Wr, Wi, channelr, channeli, Ar, Ai):\n",
        "        HBF_prer, HBF_prei = Th_comp_matmul(Ar.view(-1, self.Nrf, self.Mr).permute(0, 2, 1),\n",
        "            Ai.view(-1, self.Nrf, self.Mr).permute(0, 2, 1), Wr.permute(0, 2, 1), Wi.permute(0, 2, 1))\n",
        "\n",
        "        # power normalization over all antennas\n",
        "        temp_pre = torch.sqrt(torch.sum(HBF_prer.flatten(1) ** 2 + HBF_prei.flatten(1) ** 2, dim=1))\n",
        "        HBF_prer = (HBF_prer.flatten(1) / temp_pre.unsqueeze(1)).view(HBF_prer.shape)\n",
        "        HBF_prei = (HBF_prei.flatten(1) / temp_pre.unsqueeze(1)).view(HBF_prei.shape)\n",
        "\n",
        "        sum_rate = Loss_FDP_Rate_Based.rate_calculator(self, HBF_prer, HBF_prei, channelr, channeli)\n",
        "\n",
        "        return sum_rate.mean()\n",
        "\n",
        "def FLP_loss(x, y):\n",
        "    log_prob = - 1.0 * F.softmax(x, 1)\n",
        "    temp = log_prob * y\n",
        "    cel = temp.sum(dim=1)\n",
        "    cel = cel.mean()\n",
        "    return cel\n"
      ],
      "metadata": {
        "id": "kJKKJcsyFrGR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYECVpzV_l1i",
        "outputId": "2173545c-21ca-4c9b-e83c-11a92ef9800e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kmeans-pytorch\n",
            "  Downloading kmeans_pytorch-0.3-py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: kmeans-pytorch\n",
            "Successfully installed kmeans-pytorch-0.3\n"
          ]
        }
      ],
      "source": [
        "pip install kmeans-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryb9inmC_ZPP",
        "outputId": "981efed6-4453-41a7-942a-59eeaf31380a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running k-means on cpu..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[running kmeans]: 19it [00:00, 138.74it/s, center_shift=0.000094, iteration=19, tol=0.000100]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from kmeans_pytorch import kmeans\n",
        "\n",
        "# data\n",
        "data_size, dims, num_clusters = 1000, 2, 3\n",
        "x = np.random.randn(data_size, dims) / 6\n",
        "x = torch.from_numpy(x)\n",
        "\n",
        "# kmeans\n",
        "cluster_ids_x, cluster_centers = kmeans(\n",
        "    X=x, num_clusters=num_clusters, distance='euclidean'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JwiKCdAFclEx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class Net_m_task_CNN(nn.Module):\n",
        "    def __init__(self, n_in, n_hidden, n_out_Reg, n_out_clas, p_dropout, U, Ass, out_channel, kernel_s, padding):\n",
        "        super(Net_m_task_CNN, self).__init__()\n",
        "\n",
        "        #self.cnn1 = ComplexConv2D(4,4,in_channels=1, out_channels=16, stride=1, padding=padding)\n",
        "        \n",
        "\n",
        "        #self.cnn1 = (ComplexConv2D(4, 4, strides=1, padding='valid',\n",
        "                          #kernel_initializer='complex_independent',name='Conv_P'))(encoded)\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=kernel_s, stride=1, padding=padding)\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=16)\n",
        "        self.do1 = nn.Dropout2d(p_dropout)\n",
        "        #self.do1 = nn.AlphaDropout(p_dropout)\n",
        "        #self.do1 = nn.FeatureAlphaDropout(0.2)\n",
        "\n",
        "\n",
        "\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=kernel_s, stride=1, padding=padding)\n",
        "        self.relu2 = nn.LeakyReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=32)\n",
        "        self.do2 = nn.Dropout2d(0.2)\n",
        "\n",
        "        self.cnn3 = nn.Conv2d(in_channels=32, out_channels=8, kernel_size=kernel_s, stride=1, padding=padding)\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "        self.bn3 = nn.BatchNorm2d(num_features=8)\n",
        "        self.do3 = nn.Dropout2d(0.2)\n",
        "\n",
        "       \n",
        "        \n",
        "        #n_in1 = 8\n",
        "        #self.word_embeddings = nn.Embedding.from_pretrained(0.5, freeze=True)\n",
        "\n",
        "        self.lstm1 = nn.LSTM(1024, 512,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.do4 = nn.Dropout(0.2)\n",
        "        \n",
        "        self.rnn1 = nn.RNN(1024, 512,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.drnn1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.rnn2 = nn.RNN(512, 256,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.drnn2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.gru1 = nn.GRU(1024, 512,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.dgru1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.gru2 = nn.GRU(512, 256,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.dgru2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.lstm2 = nn.LSTM(512, 256,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.do5 = nn.Dropout(0.2)\n",
        "\n",
        "        #self.lstm3 = nn.LSTM(32, n_in,\n",
        "                            #bidirectional=True, batch_first=True)\n",
        "        \n",
        "        #self.do6 = nn.Dropout(p_dropout)\n",
        "#end\n",
        "\n",
        "\n",
        "        # Fully connected 1 (readout)\n",
        "        x_new = (U + 2 * padding - kernel_s) + 1\n",
        "        y_new = (Ass + 2 * padding - kernel_s) + 1\n",
        "\n",
        "        nn_in_fc = 8 * (x_new + 2 * padding - kernel_s + 1) * (y_new + 2 * padding - kernel_s + 1)\n",
        "\n",
        "\n",
        "        self.fc20 = nn.Linear(nn_in_fc, n_hidden)\n",
        "        self.bn20 = nn.BatchNorm1d(n_hidden)\n",
        "        self.relu20 = nn.LeakyReLU()\n",
        "        self.do20 = nn.Dropout(p_dropout)\n",
        "\n",
        "        self.fc30 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.bn30 = nn.BatchNorm1d(n_hidden)\n",
        "        self.relu30 = nn.LeakyReLU()\n",
        "        self.do30 = nn.Dropout(p_dropout)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        self.fc7R = nn.Linear(n_hidden, n_out_Reg)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        self.fc8R = nn.Linear(n_hidden, n_out_Reg)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        self.fc9C = nn.Linear(n_hidden, n_out_clas)\n",
        "\n",
        "    def forward(self, x):  # always\n",
        "\n",
        "        out = self.cnn1(x)\n",
        "        out = self.do1(out)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        out = self.cnn2(out)\n",
        "        out = self.do2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        out = self.cnn3(out)\n",
        "        out = self.do3(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu3(out)\n",
        "\n",
        "        #m6\n",
        "        #out= torch.flatten(out)\n",
        "        #out= out[0:131072]\n",
        "        out = out.view(-1,1024)\n",
        "        #out = out.view(-1,64)\n",
        "        #out = self.lstm1(out)\n",
        "        #out = self.do4(out[0])\n",
        "\n",
        "        out = self.rnn1(out)\n",
        "        out = self.drnn1(out[0])\n",
        "        #out = out.view(-1,512)\n",
        "        #out = self.rnn2(out)\n",
        "        #out = self.drnn2(out[0])        \n",
        "\n",
        "        #out = torch.flatten(out)\n",
        "        #out = out.view(-1,512)\n",
        "        #out = self.lstm2(out)\n",
        "        #out = self.do5(out[0])  \n",
        "\n",
        "        #out = self.lstm3(out)\n",
        "        #out = self.do6(out)     \n",
        "        #out = torch.flatten(out)\n",
        "        #out = out.view(-1,1024)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        out = self.fc20(out)\n",
        "        out = self.do20(out)\n",
        "        out = self.relu20(out)\n",
        "        out = self.bn20(out)\n",
        "\n",
        "        out = self.fc30(out)\n",
        "        out = self.do30(out)\n",
        "        out = self.relu30(out)\n",
        "        out = self.bn30(out)\n",
        "        #out= torch.flatten(out)\n",
        "        #out= out[1:131073]\n",
        "        #out = out.view(-1, 1024)\n",
        "        #out = self.lstm1(out)\n",
        "        #out = self.do4(out[0])\n",
        "        # Linear function (readout)  ****** LINEAR ******\n",
        "        outR1 = self.fc7R(out)\n",
        "\n",
        "        # Linear function (readout)  ****** LINEAR ******\n",
        "        #outR2 = self.fc8R(out)\n",
        "        outR2 = self.fc8R(out)\n",
        "        # Linear function (readout)  ****** LINEAR ******\n",
        "        outC = self.fc9C(out)\n",
        "\n",
        "        return outR1, outR2,outC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FuoWyeN0b-Ja"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class Net_m_task_CNN(nn.Module):\n",
        "    def __init__(self, n_in, n_hidden, n_out_Reg, n_out_clas, p_dropout, U, Ass, out_channel, kernel_s, padding):\n",
        "        super(Net_m_task_CNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_channel, kernel_size=kernel_s, stride=1, padding=padding)\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=out_channel)\n",
        "        self.do1 = nn.Dropout2d(p_dropout)\n",
        "\n",
        "        self.cnn2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=kernel_s, stride=1, padding=padding)\n",
        "        self.relu2 = nn.LeakyReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=out_channel)\n",
        "        self.do2 = nn.Dropout2d(p_dropout)\n",
        "\n",
        "        self.cnn3 = nn.Conv2d(in_channels=out_channel, out_channels=8, kernel_size=kernel_s, stride=1, padding=padding)\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "        self.bn3 = nn.BatchNorm2d(num_features=8)\n",
        "        self.do3 = nn.Dropout2d(p_dropout)\n",
        "\n",
        "        # Fully connected 1 (readout)\n",
        "        x_new = (U + 2 * padding - kernel_s) + 1\n",
        "        y_new = (Ass + 2 * padding - kernel_s) + 1\n",
        "\n",
        "        nn_in_fc = 8 * (x_new + 2 * padding - kernel_s + 1) * (y_new + 2 * padding - kernel_s + 1)\n",
        "\n",
        "        self.fc20 = nn.Linear(nn_in_fc, n_hidden)\n",
        "        self.bn20 = nn.BatchNorm1d(n_hidden)\n",
        "        self.relu20 = nn.LeakyReLU()\n",
        "        self.do20 = nn.Dropout(p_dropout)\n",
        "\n",
        "        self.fc30 = nn.Linear(n_hidden, n_hidden)\n",
        "        self.bn30 = nn.BatchNorm1d(n_hidden)\n",
        "        self.relu30 = nn.LeakyReLU()\n",
        "        self.do30 = nn.Dropout(p_dropout)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        self.fc7R = nn.Linear(n_hidden, n_out_Reg)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        self.fc8R = nn.Linear(n_hidden, n_out_Reg)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        self.fc9C = nn.Linear(n_hidden, n_out_clas)\n",
        "\n",
        "    def forward(self, x):  # always\n",
        "\n",
        "        out = self.cnn1(x)\n",
        "        out = self.do1(out)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        #out = self.cnn2(out)\n",
        "        #out = self.do2(out)\n",
        "        #out = self.bn2(out)\n",
        "        #out = self.relu2(out)\n",
        "\n",
        "        out = self.cnn3(out)\n",
        "        out = self.do3(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu3(out)\n",
        "\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        out = self.fc20(out)\n",
        "        out = self.do20(out)\n",
        "        out = self.relu20(out)\n",
        "        out = self.bn20(out)\n",
        "\n",
        "        out = self.fc30(out)\n",
        "        out = self.do30(out)\n",
        "        out = self.relu30(out)\n",
        "        out = self.bn30(out)\n",
        "\n",
        "        # Linear function (readout)  ****** LINEAR ******\n",
        "        outR1 = self.fc7R(out)\n",
        "\n",
        "        # Linear function (readout)  ****** LINEAR ******\n",
        "        outR2 = self.fc8R(out)\n",
        "\n",
        "        # Linear function (readout)  ****** LINEAR ******\n",
        "        outC = self.fc9C(out)\n",
        "\n",
        "        return outR1, outR2, outC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4XO9qeaycqQn"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "class Networks_activations(object):\n",
        "    def __init__(self,\n",
        "                 Us,\n",
        "                 Mr,\n",
        "                 Nrf,\n",
        "                 K,\n",
        "                 K_limited,\n",
        "                 Noise_pwr,\n",
        "                 device,\n",
        "                 device_ids,\n",
        "                 n_input,\n",
        "                 n_hidden,\n",
        "                 n_output_reg,\n",
        "                 n_output_clas,\n",
        "                 p_dropout,\n",
        "                 out_channel,\n",
        "                 kernel_s,\n",
        "                 padding\n",
        "                 ):\n",
        "        self.Us = Us\n",
        "        self.Mr = Mr\n",
        "        self.Nrf = Nrf\n",
        "        self.K = K\n",
        "        self.K_limited = K_limited\n",
        "        self.Noise_pwr = Noise_pwr\n",
        "        self.device = device\n",
        "        self.dev_id = device_ids\n",
        "        self.n_input = n_input\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_output_reg = n_output_reg\n",
        "        self.n_output_clas = n_output_clas\n",
        "        self.p_dropout = p_dropout\n",
        "        self.out_channel = out_channel\n",
        "        self.kernel_s = kernel_s\n",
        "        self.padding = padding\n",
        "        \n",
        "    def Network_m_Task(self):\n",
        "        if self.device.type == 'cuda':\n",
        "            return nn.DataParallel(Net_m_task_CNN(self.n_input, self.n_hidden, self.n_output_reg, self.n_output_clas, self.p_dropout, self.Us, self.K_limited, self.out_channel, self.kernel_s, self.padding), device_ids=self.dev_id).to(self.device)\n",
        "        else:\n",
        "            return Net_m_task_CNN(self.n_input, self.n_hidden, self.n_output_reg, self.n_output_clas,\n",
        "                self.p_dropout, self.Us, self.K_limited, self.out_channel, self.kernel_s, self.padding)\n",
        "\n",
        "    def Inp_MT(self, RSSI):\n",
        "        #transformer = IncrementalPCA(n_components=12, batch_size=64000)\n",
        "\n",
        "        #Inputs_MT1 = RSSI.reshape(len(RSSI), 1, self.Us, self.K)[:, :, :, 0:self.K_limited].float().to(self.device)\n",
        "        #X_sparse = sparse.csr_matrix(RSSI)\n",
        "\n",
        "        #Inputs_MT2 = transformer.fit_transform(X_sparse)\n",
        "        #RSSI =torch.Tensor(Inputs_MT2)\n",
        "        #Inputs_MT = RSSI.reshape(len(RSSI), 1, self.Us, self.K)[:, :, :, 0:self.K_limited].float().to(self.device)        \n",
        "        Inputs_MT = RSSI.reshape(len(RSSI), 1, self.Us, self.K)[:, :, :, 0:self.K_limited].float().to(self.device)\n",
        "        return Inputs_MT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7npOKnnJcypf",
        "outputId": "49a3a7c5-da9e-4abe-c573-d52dd61cc2bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Cuda available?  False\n",
            "Which devide? cpu\n",
            "You select core dataset\n",
            "DataBase_dataSet64x8x4_130dB_0129201820.npy is loading ... \n",
            "The number of Unique AP in I1:  5\n",
            "The length of the codebook:  5\n",
            "The size of training set is  8568\n",
            "The size of Test set is  1512\n",
            "Iter:==>  1 Loss_FDP:-0.390 Loss_Class:-1.016 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:1.42 Rate_pre_FDP:0.92 Ratio_HBF:26.81% Ratio_FDP:16.09%\n",
            "Iter:==>  2 Loss_FDP:-4.292 Loss_Class:-4.185 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:3.87 Rate_pre_FDP:3.94 Ratio_HBF:72.88% Ratio_FDP:69.30%\n",
            "Iter:==>  3 Loss_FDP:-4.425 Loss_Class:-4.286 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.27 Rate_pre_FDP:4.41 Ratio_HBF:80.33% Ratio_FDP:77.52%\n",
            "Iter:==>  4 Loss_FDP:-4.429 Loss_Class:-4.296 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.46 Rate_pre_FDP:4.60 Ratio_HBF:83.91% Ratio_FDP:80.90%\n",
            "Iter:==>  5 Loss_FDP:-4.732 Loss_Class:-4.574 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.70 Rate_pre_FDP:4.87 Ratio_HBF:88.49% Ratio_FDP:85.55%\n",
            "Iter:==>  6 Loss_FDP:-4.591 Loss_Class:-4.446 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.68 Rate_pre_FDP:4.86 Ratio_HBF:88.01% Ratio_FDP:85.32%\n",
            "Iter:==>  7 Loss_FDP:-4.599 Loss_Class:-4.449 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.68 Rate_pre_FDP:4.86 Ratio_HBF:88.17% Ratio_FDP:85.46%\n",
            "Iter:==>  8 Loss_FDP:-4.581 Loss_Class:-4.429 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.74 Rate_pre_FDP:4.92 Ratio_HBF:89.30% Ratio_FDP:86.36%\n",
            "Iter:==>  9 Loss_FDP:-4.565 Loss_Class:-4.403 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.78 Rate_pre_FDP:4.97 Ratio_HBF:89.96% Ratio_FDP:87.35%\n",
            "Iter:==> 10 Loss_FDP:-4.668 Loss_Class:-4.510 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.73 Rate_pre_FDP:4.92 Ratio_HBF:89.03% Ratio_FDP:86.49%\n",
            "Iter:==> 11 Loss_FDP:-4.658 Loss_Class:-4.475 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.78 Rate_pre_FDP:4.97 Ratio_HBF:89.88% Ratio_FDP:87.40%\n",
            "Iter:==> 12 Loss_FDP:-4.641 Loss_Class:-4.470 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.78 Rate_pre_FDP:4.98 Ratio_HBF:89.93% Ratio_FDP:87.54%\n",
            "Iter:==> 13 Loss_FDP:-4.711 Loss_Class:-4.534 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.74 Rate_pre_FDP:4.95 Ratio_HBF:89.13% Ratio_FDP:87.03%\n",
            "Iter:==> 14 Loss_FDP:-4.667 Loss_Class:-4.492 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.77 Rate_pre_FDP:4.97 Ratio_HBF:89.74% Ratio_FDP:87.37%\n",
            "Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Iter:==> 15 Loss_FDP:-4.728 Loss_Class:-4.556 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.74 Rate_pre_FDP:4.95 Ratio_HBF:89.19% Ratio_FDP:86.92%\n",
            "Iter:==> 16 Loss_FDP:-4.653 Loss_Class:-4.478 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.79 Rate_pre_FDP:5.00 Ratio_HBF:90.23% Ratio_FDP:87.90%\n",
            "Iter:==> 17 Loss_FDP:-4.623 Loss_Class:-4.448 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.81 Rate_pre_FDP:5.02 Ratio_HBF:90.57% Ratio_FDP:88.26%\n",
            "Iter:==> 18 Loss_FDP:-4.612 Loss_Class:-4.434 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.82 Rate_pre_FDP:5.03 Ratio_HBF:90.69% Ratio_FDP:88.38%\n",
            "Iter:==> 19 Loss_FDP:-4.733 Loss_Class:-4.550 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.82 Rate_pre_FDP:5.03 Ratio_HBF:90.79% Ratio_FDP:88.43%\n",
            "Iter:==> 20 Loss_FDP:-4.701 Loss_Class:-4.523 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.83 Rate_pre_FDP:5.04 Ratio_HBF:90.84% Ratio_FDP:88.51%\n",
            "Iter:==> 21 Loss_FDP:-4.730 Loss_Class:-4.541 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.82 Rate_pre_FDP:5.04 Ratio_HBF:90.80% Ratio_FDP:88.53%\n",
            "Iter:==> 22 Loss_FDP:-4.596 Loss_Class:-4.422 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.83 Rate_pre_FDP:5.04 Ratio_HBF:90.84% Ratio_FDP:88.50%\n",
            "Iter:==> 23 Loss_FDP:-4.528 Loss_Class:-4.350 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.82 Rate_pre_FDP:5.04 Ratio_HBF:90.73% Ratio_FDP:88.47%\n",
            "Iter:==> 24 Loss_FDP:-4.646 Loss_Class:-4.468 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.83 Rate_pre_FDP:5.04 Ratio_HBF:90.86% Ratio_FDP:88.59%\n",
            "Iter:==> 25 Loss_FDP:-4.658 Loss_Class:-4.482 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.82 Rate_pre_FDP:5.04 Ratio_HBF:90.78% Ratio_FDP:88.49%\n",
            "Iter:==> 26 Loss_FDP:-4.762 Loss_Class:-4.576 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.82 Rate_pre_FDP:5.04 Ratio_HBF:90.79% Ratio_FDP:88.52%\n",
            "Iter:==> 27 Loss_FDP:-4.692 Loss_Class:-4.516 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.82 Rate_pre_FDP:5.03 Ratio_HBF:90.73% Ratio_FDP:88.44%\n",
            "Iter:==> 28 Loss_FDP:-4.640 Loss_Class:-4.468 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.83 Rate_pre_FDP:5.04 Ratio_HBF:90.88% Ratio_FDP:88.60%\n",
            "Iter:==> 29 Loss_FDP:-4.535 Loss_Class:-4.368 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.83 Rate_pre_FDP:5.04 Ratio_HBF:90.82% Ratio_FDP:88.54%\n",
            "Iter:==> 30 Loss_FDP:-4.746 Loss_Class:-4.568 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.83 Rate_pre_FDP:5.04 Ratio_HBF:90.82% Ratio_FDP:88.55%\n",
            "Iter:==> 31 Loss_FDP:-4.676 Loss_Class:-4.489 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.82 Rate_pre_FDP:5.04 Ratio_HBF:90.76% Ratio_FDP:88.51%\n",
            "Iter:==> 32 Loss_FDP:-4.698 Loss_Class:-4.524 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.82 Rate_pre_FDP:5.03 Ratio_HBF:90.67% Ratio_FDP:88.39%\n",
            "Iter:==> 33 Loss_FDP:-4.742 Loss_Class:-4.555 Rate_opt_HBF:5.31 Rate_opt_FDP:5.69 Rate_pre_HBF:4.81 Rate_pre_FDP:5.02 Ratio_HBF:90.44% Ratio_FDP:88.14%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/HBF-Net-main')\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from numpy import genfromtxt\n",
        "import torch as th\n",
        "\n",
        "from termcolor import colored\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import SparsePCA\n",
        "from scipy import sparse\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "###############################################################################\n",
        "# Directory file\n",
        "###############################################################################\n",
        "DB_name = 'dataSet64x8x4_130dB_0129201820'\n",
        "#DB_name = 'pro_channel_BS32_2p4GHz_1Path'\n",
        "\n",
        "###############################################################################\n",
        "# Processor selection GPU if available (using GPU is highly recommended)\n",
        "###############################################################################\n",
        "device = th.device(\"cuda:2\" if th.cuda.is_available() else \"cpu\")\n",
        "device_ids = [2, 1, 3]\n",
        "print(\"Is Cuda available? \", colored('True', 'green')\n",
        "    if th.cuda.is_available() else colored('False', 'red'))\n",
        "print(\"Which devide?\", colored(device, 'cyan'))\n",
        "\n",
        "###############################################################################\n",
        "# Setup Parameters\n",
        "###############################################################################\n",
        "\n",
        "# Beamforming approach  AFP_Net, HBF_NET   ####################################\n",
        "#BF_approach = 'HBF_Net'\n",
        "BF_approach = 'AFP_Net'\n",
        "###############################################################################\n",
        "# Beamfroming system model and DNN Parameters\n",
        "###############################################################################\n",
        "os.chdir(os.path.dirname(os.path.abspath('/content/drive/MyDrive/HBF-Net-main/pro_channel_BS32_2p4GHz_1Path.npy')))\n",
        "Us, Mr, Nrf, K, Noise_pwr = md_reader(DB_name)                # Number of users, antenna, K, RF chains and noise power\n",
        "#m6\n",
        "#Us=8\n",
        "#Mr=128\n",
        "#Noise_pwr =120\n",
        "#K=\n",
        "#end\n",
        "\n",
        "\n",
        "K_limited = K                                                 # Number of SS as RSSI\n",
        "batch_size = 500                                          # Batch size\n",
        "epoch_size = 100                                         # Number of training epoches\n",
        "#lr = 0.001 \n",
        "lr = 0.001                                                # Learning rate\n",
        "#wd = 1e-6 \n",
        "wd = 1e-9                                                      # Weight decay\n",
        "n_input = Us * K_limited                                      # Input dimensions\n",
        "n_hidden = 1024                                         # Size of FCL layers\n",
        "out_channel = 16                                              # Size of CL channels\n",
        "kernel_s = 3                                                  # Size of Kernels in CL\n",
        "padding = 1                                                   # Size of padding in CL\n",
        "p_dropout = 0.05                                              # Probability of dropout\n",
        "\n",
        "\n",
        "\n",
        "if BF_approach == 'HBF_Net':\n",
        "    n_output_reg = Us * Nrf\n",
        "elif BF_approach == 'AFP_Net':\n",
        "    n_output_reg = Us * Mr\n",
        "else:\n",
        "    raise Exception('BF_approach value is wrong !!')\n",
        "\n",
        "###############################################################################\n",
        "# Main Menu of configuration\n",
        "###############################################################################\n",
        "#my line\n",
        "\n",
        "#end my line\n",
        "\n",
        "Main_Menu = Initialization_Model_Params(DB_name,\n",
        "                                        Us,\n",
        "                                        Mr,\n",
        "                                        Nrf,\n",
        "                                        K,\n",
        "                                        K_limited,\n",
        "                                        Noise_pwr,\n",
        "                                        device,\n",
        "                                        device_ids)\n",
        "\n",
        "###############################################################################\n",
        "# Reading Database\n",
        "###############################################################################\n",
        "DataBase, uniq_dis_label = Main_Menu.Data_Load()\n",
        "\n",
        "###############################################################################\n",
        "# Codeword dictionary\n",
        "###############################################################################\n",
        "#codeword_C, n_output_clas, codesr, codesi = Main_Menu.Code_Read()\n",
        "codeword_C, n_output_clas, codesr, codesi = Main_Menu.Code_Read()\n",
        "###############################################################################\n",
        "# Training-set and test-set generation\n",
        "###############################################################################\n",
        "train_size = int(0.85 * len(DataBase))\n",
        "test_size = len(DataBase) - train_size\n",
        "train_dataset, test_dataset = th.utils.data.random_split(DataBase, [train_size, test_size])\n",
        "\n",
        "print(colored('The size of training set is ', 'yellow'), len(train_dataset))\n",
        "print(colored('The size of Test set is ', 'yellow'), len(test_dataset))\n",
        "\n",
        "###############################################################################\n",
        "# Dataloaders\n",
        "###############################################################################\n",
        "my_dataloader = th.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "my_testloader = th.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "###############################################################################\n",
        "# DNN architecture parameters\n",
        "###############################################################################\n",
        "Networks_Main_Menu = Networks_activations(Us,\n",
        "                                        Mr,\n",
        "                                        Nrf,\n",
        "                                        K,\n",
        "                                        K_limited,\n",
        "                                        Noise_pwr,\n",
        "                                        device,\n",
        "                                        device_ids,\n",
        "                                        n_input,\n",
        "                                        n_hidden,\n",
        "                                        n_output_reg,\n",
        "                                        n_output_clas,\n",
        "                                        p_dropout,\n",
        "                                        out_channel,\n",
        "                                        kernel_s,\n",
        "                                        padding)\n",
        "\n",
        "Model_m_task = Networks_Main_Menu.Network_m_Task()\n",
        "\n",
        "###############################################################################\n",
        "# DNN OPTIMIZER\n",
        "###############################################################################\n",
        "optimizer_m_task = th.optim.Adam(Model_m_task.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "###############################################################################\n",
        "# scheduler lr\n",
        "###############################################################################\n",
        "scheduler_MT = ReduceLROnPlateau(optimizer_m_task, mode='max', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "###############################################################################\n",
        "# Main training loop\n",
        "###############################################################################\n",
        "if BF_approach == 'AFP_Net':\n",
        "    # initialing the loss function\n",
        "    criterium_clas_4d = Loss_HBF_Rate_Based_4D(Us, Mr, Nrf, Noise_pwr).to(device)\n",
        "    criterium_reg = Loss_FDP_Rate_Based(Us, Mr, Nrf, Noise_pwr).to(device)\n",
        "    loss_clas1=[]\n",
        "    RATE_Predicted_HBF1= [] \n",
        "    RATE_Optimum_HBF1= []\n",
        "\n",
        "\n",
        "    for i in range(1, epoch_size):   # Main traning loop\n",
        "        for k, (channelR, channelI, alpha, RSSI, UR, UI, AR, AI, index, WR, WI, deltaR, deltaI, userp) in enumerate(my_dataloader):  # Loading data from data loader\n",
        "            \n",
        "            \n",
        "            #transformer = IncrementalPCA(n_components=128, batch_size=500)\n",
        "            #X_sparse = sparse.csr_matrix(RSSI)\n",
        "            #np_data2 = transformer.fit_transform(X_sparse)\n",
        "\n",
        "\n",
        "            # Input data dimension check (CNN)\n",
        "            #Inputs_MT = Networks_Main_Menu.Inp_MT(np_data2)\n",
        "            Inputs_MT = Networks_Main_Menu.Inp_MT(RSSI)\n",
        "\n",
        "            # Loading the CSI (real and imaginary)\n",
        "            channelR = channelR.view(-1, Us, Mr).to(device)\n",
        "            channelI = channelI.view(-1, Us, Mr).to(device)\n",
        "\n",
        "            # Set gradient to 0.\n",
        "            optimizer_m_task.zero_grad()\n",
        "\n",
        "            # Feed forward multi-tasking DNN\n",
        "            Model_m_task.train()\n",
        "            out1_reg, out2_reg, out_clas = Model_m_task(Inputs_MT)\n",
        "\n",
        "            # Computing loss for FDP in AFP-Net eq(27) in the paper\n",
        "            loss_reg = criterium_reg(out1_reg, out2_reg, channelR, channelI)\n",
        "\n",
        "            # computing the loss fucntion for HBF using eq(20)\n",
        "            xx_pr, xx_pi = Th_pinv(th.unsqueeze(codesr.unsqueeze(1), 2).repeat(1, len(RSSI), 1, 1).view(-1, len(RSSI), Nrf, Mr).to(device),\n",
        "                th.unsqueeze(codesi.unsqueeze(1), 2).repeat(1, len(RSSI), 1, 1).view(-1, len(RSSI), Nrf, Mr).to(device))\n",
        "            w_outr, w_outi = Th_comp_matmul(out1_reg.view(-1, Us, Mr), out2_reg.view(-1, Us, Mr), xx_pr, xx_pi)\n",
        "\n",
        "            HBF_all_4d = criterium_clas_4d(w_outr.permute(0, 1, 3, 2), w_outi.permute(0, 1, 3, 2), channelR, channelI,\n",
        "                th.unsqueeze(codesr.unsqueeze(1), 2).repeat(1, len(RSSI), 1, 1).to(device), th.unsqueeze(codesi.unsqueeze(1), 2).repeat(1, len(RSSI), 1, 1).to(device))\n",
        "\n",
        "            loss_clas = FLP_loss(out_clas, HBF_all_4d)\n",
        "\n",
        "            # total loss fucntion eq(29)\n",
        "            loss = loss_clas + loss_reg\n",
        "\n",
        "            # Gradient calculation.\n",
        "            loss_clas.backward(retain_graph=True)\n",
        "            loss_reg.backward(retain_graph=True)\n",
        "            loss.backward()\n",
        "            loss_clas1.append(loss_clas)\n",
        "            # Model weight modification based on the optimizer.\n",
        "            optimizer_m_task.step()\n",
        "\n",
        "            # iterate through test dataset\n",
        "            if k == 0 or i % epoch_size == 0:\n",
        "                del loss\n",
        "                # No gardient in test mode\n",
        "                with th.no_grad():\n",
        "                    R_predicted_HBF = []\n",
        "                    R_optimum_HBF = []\n",
        "                    R_optimum_FDP = []\n",
        "                    R_predicted_FDP = []\n",
        "                    Rate_Ratio_HBF = []\n",
        "                    Rate_Ratio_FDP = []\n",
        "                    w_prer= []\n",
        "                    w_prei= []               \n",
        "                    An_Predr= []  \n",
        "                    An_Predi   = [] \n",
        "                    T_channelR= [] \n",
        "                    T_channelI= [] \n",
        "\n",
        "                    for (tchannelR, tchannelI, talpha, tRSSI, tUR, tUI, tAR, tAI, tindex, tWR, tWI, tdeltaR, tdeltaI, tup) in my_testloader:\n",
        "\n",
        "                        # Input data dimension check (CNN)\n",
        "                        testInputs_Reg = Networks_Main_Menu.Inp_MT(tRSSI)\n",
        "\n",
        "                        # Loading the near-optimal digital precoder, CSI (real and imaginary)\n",
        "                        T_wR = tWR.reshape(-1, Us, Nrf).to(device)\n",
        "                        T_wI = tWI.reshape(-1, Us, Nrf).to(device)\n",
        "                        T_channelR = tchannelR.reshape(-1, Us, Mr).to(device)\n",
        "                        T_channelI = tchannelI.reshape(-1, Us, Mr).to(device)\n",
        "\n",
        "                        # Forward pass test mode DNN\n",
        "                        Model_m_task.eval()\n",
        "                        pred1_reg, pred2_reg, pred_class = Model_m_task(testInputs_Reg)\n",
        "\n",
        "                        # find the maximum probability as predication of classification\n",
        "                        _, predicted = th.max(F.softmax(pred_class, 1), 1)\n",
        "\n",
        "                        # mapping in the codebook to find the corresponding analog precoder\n",
        "                        An_Predr = codesr[predicted, :].to(device)\n",
        "                        An_Predi = codesi[predicted, :].to(device)\n",
        "\n",
        "                        # finding digital precoder using eq(20)\n",
        "                        x_pr, x_pi = Th_pinv(An_Predr.view(-1, Nrf, Mr), An_Predi.view(-1, Nrf, Mr))\n",
        "                        w_prer, w_prei = Th_comp_matmul(pred1_reg.view(-1, Us, Mr), pred2_reg.view(-1, Us, Mr), x_pr, x_pi)\n",
        "\n",
        "                        # rate calculation\n",
        "                        # DNN HBF\n",
        "                        R_predicted_HBF.append(criterium_clas_4d.evaluate_rate(w_prer, w_prei, T_channelR, T_channelI, An_Predr, An_Predi))\n",
        "                        # near-optimal HBF\n",
        "                        R_optimum_HBF.append(criterium_clas_4d.evaluate_rate(T_wR, T_wI, T_channelR, T_channelI, tAR.to(device), tAI.to(device)))\n",
        "                        # DNN FDP\n",
        "                        R_predicted_FDP.append(criterium_reg.evaluate_rate(pred1_reg, pred2_reg, T_channelR, T_channelI))\n",
        "                        # near-optimal HBF\n",
        "                        R_optimum_FDP.append(criterium_reg.evaluate_rate(tUR.to(device), tUI.to(device), T_channelR, T_channelI))\n",
        "\n",
        "                # Average over all mini-batches\n",
        "                RATE_Predicted_HBF = sum(R_predicted_HBF) / len(R_predicted_HBF)\n",
        "                RATE_Predicted_FDP = sum(R_predicted_FDP) / len(R_predicted_FDP)\n",
        "                RATE_Optimum_HBF = sum(R_optimum_HBF) / len(R_optimum_HBF)\n",
        "                RATE_Optimum_FDP = sum(R_optimum_FDP) / len(R_optimum_FDP)\n",
        "                RATE_Ratie_HBF = 100 * RATE_Predicted_HBF / RATE_Optimum_HBF\n",
        "                RATE_Ratie_FDP = 100 * RATE_Predicted_FDP / RATE_Optimum_FDP\n",
        "                RATE_Predicted_HBF1.append(RATE_Predicted_HBF)\n",
        "                RATE_Optimum_HBF1.append(RATE_Optimum_HBF)\n",
        "                scheduler_MT.step(RATE_Predicted_HBF)\n",
        "\n",
        "                print('Iter:==>{:3d} Loss_FDP:{:.3f} Loss_Class:{:.3f} Rate_opt_HBF:{:.2f} Rate_opt_FDP:{:.2f} Rate_pre_HBF:{:.2f} Rate_pre_FDP:{:.2f} Ratio_HBF:{:.2f}% Ratio_FDP:{:.2f}%'.\n",
        "                    format(i, loss_reg, loss_clas, RATE_Optimum_HBF, RATE_Optimum_FDP, RATE_Predicted_HBF, RATE_Predicted_FDP, RATE_Ratie_HBF, RATE_Ratie_FDP))\n",
        "\n",
        "elif BF_approach == 'HBF_Net':\n",
        "    # initialing the loss function\n",
        "    criterium_clas_4d = Loss_HBF_Rate_Based_4D(Us, Mr, Nrf, Noise_pwr).to(device)\n",
        "    #my line\n",
        "    loss_clas1=[]\n",
        "    R_predicted_HBF = []\n",
        "    R_optimum_HBF = [] \n",
        "    RATE_Predicted_HBF1= [] \n",
        "    RATE_Optimum_HBF1= []\n",
        "    out1_reg1= []\n",
        "    out2_reg1= []\n",
        "    out_clas1= []\n",
        "\n",
        "    for i in range(1, epoch_size):\n",
        "      \n",
        "        for k, (channelR, channelI, alpha, RSSI, UR, UI, AR, AI, index, WR, WI, deltaR, deltaI, userp) in enumerate(my_dataloader):\n",
        "            #m6\n",
        "            #file3=np.load('/content/drive/MyDrive/HBF-Net-main/pcaorpca.npy')\n",
        "            #a4=np.abs(file3)\n",
        "            #a5=np.max(a4)\n",
        "            #a6=np.min(a4)\n",
        "            #a7=(a4-a6)/(a5-a6)\n",
        "            #RSSI= a7[:64, (Us * Mr) + (Us * K):(Us * Mr) + (2 * Us * K)].real.astype(float)\n",
        "            #e\n",
        "            # Input data dimension check (CNN)\n",
        "            #m6\n",
        "            #noise = np.random.normal(0, 0.05, RSSI.shape)\n",
        "            #RSSI = RSSI + noise\n",
        "            #sc = StandardScaler()\n",
        "      \n",
        "            #X_train = sc.fit_transform(RSSI)\n",
        "            #pca = PCA(n_components = 8)\n",
        "  \n",
        "            #RSSI1 = pca.fit_transform(X_train)  \n",
        "            #RSSI =torch.Tensor(RSSI1)          \n",
        "            #e\n",
        "            Inputs_Reg = Networks_Main_Menu.Inp_MT(RSSI)\n",
        "\n",
        "            # Loading the CSI (real and imaginary)\n",
        "            channelR = channelR.view(-1, Us, Mr).to(device)\n",
        "            channelI = channelI.view(-1, Us, Mr).to(device)\n",
        "\n",
        "            # Set gradient to 0.\n",
        "            optimizer_m_task.zero_grad()\n",
        "\n",
        "            # Feed forward multi-tasking DNN\n",
        "            Model_m_task.train()  #edited\n",
        "            out1_reg, out2_reg, out_clas = Model_m_task(Inputs_Reg)\n",
        "\n",
        "            # computing the loss fucntion for HBF using eq(25)\n",
        "            w_outr, w_outi = out1_reg.view(-1, Us, Nrf), out2_reg.view(-1, Us, Nrf)\n",
        "            HBF_all_4d = criterium_clas_4d(w_outr.permute(0, 2, 1), w_outi.permute(0, 2, 1), channelR, channelI,\n",
        "                th.unsqueeze(codesr.unsqueeze(1), 2).repeat(1, len(RSSI), 1, 1).to(device),\n",
        "                th.unsqueeze(codesi.unsqueeze(1), 2).repeat(1, len(RSSI), 1, 1).to(device))\n",
        "            #loss_clas = FLP_loss(out_clas, HBF_all_4d)\n",
        "            loss_clas = FLP_loss(out_clas, HBF_all_4d)\n",
        "\n",
        "            #loss = nn.CrossEntropyLoss()\n",
        "            #input = torch.randn(3, 5, requires_grad=True)\n",
        "            #target = torch.randn(3, 5)\n",
        "            #loss_clas = -loss(out_clas, HBF_all_4d)\n",
        "\n",
        "            # Gradient calculation.\n",
        "            loss_clas.backward()\n",
        "            #m6\n",
        "            loss_clas1.append(loss_clas)\n",
        "            #out1_reg1.append(out1_reg)\n",
        "            #out2_reg1.append(out2_reg)\n",
        "            #out_clas1.append(out_clas)\n",
        "            #e\n",
        "            \n",
        "            # Model weight modification based on the optimizer.\n",
        "            optimizer_m_task.step()\n",
        "          \n",
        "            \n",
        "            # iterate through test dataset\n",
        "            if k == 0 or i % epoch_size == 0:\n",
        "                #R_predicted_HBF = []\n",
        "                #R_optimum_HBF = []\n",
        "                w_prer= []\n",
        "                w_prei= []               \n",
        "                An_Predr= []  \n",
        "                An_Predi   = []      \n",
        "                T_channelR = []  \n",
        "                T_channelI = []  \n",
        "\n",
        "                with th.no_grad():\n",
        "                    for (tchannelR, tchannelI, talpha, tRSSI, tUR, tUI, tAR, tAI, tindex, tWR, tWI, tdeltaR, tdeltaI, tup) in my_testloader:\n",
        "\n",
        "                        # Input data dimension check (CNN)\n",
        "                        #m6\n",
        "                        #noise1 = np.random.normal(0, .1, tRSSI.shape)\n",
        "                        #tRSSI = tRSSI + noise1\n",
        "                        #sc = StandardScaler()\n",
        "      \n",
        "                        #X_train = sc.fit_transform(tRSSI)\n",
        "                        #pca = PCA(n_components = 8)\n",
        "  \n",
        "                        #tRSSI1 = pca.fit_transform(X_train)  \n",
        "                        #tRSSI =torch.Tensor(tRSSI1)                       \n",
        "                        #e\n",
        "                        testInputs_Reg = Networks_Main_Menu.Inp_MT(tRSSI)\n",
        "\n",
        "                        # Loading the near-optimal digital precoder, CSI (real and imaginary)\n",
        "                        T_wR = tWR.reshape(-1, Us, Nrf).to(device)\n",
        "                        T_wI = tWI.reshape(-1, Us, Nrf).to(device)\n",
        "                        T_channelR = tchannelR.reshape(-1, Us, Mr).to(device)\n",
        "                        T_channelI = tchannelI.reshape(-1, Us, Mr).to(device)\n",
        "\n",
        "                        # Forward pass reg\n",
        "                        Model_m_task.eval()\n",
        "                        pred1_reg, pred2_reg, pred_class = Model_m_task(testInputs_Reg)\n",
        "\n",
        "                        # find the maximum probability as predication of classification\n",
        "                        _, predicted = th.max(F.softmax(pred_class, 1), 1)\n",
        "\n",
        "                        # mapping in the codebook to find the corresponding analog precoder\n",
        "                        An_Predr = codesr[predicted, :].to(device)\n",
        "                        An_Predi = codesi[predicted, :].to(device)\n",
        "                        w_prer, w_prei = pred1_reg.view(-1, Us, Nrf), pred2_reg.view(-1, Us, Nrf)\n",
        "\n",
        "                        # rate calculation\n",
        "                        # DNN HBF\n",
        "                        R_predicted_HBF.append(criterium_clas_4d.evaluate_rate(w_prer, w_prei, T_channelR, T_channelI, An_Predr, An_Predi))\n",
        "                        \n",
        "                        # near-optimal HBF\n",
        "                        R_optimum_HBF.append(criterium_clas_4d.evaluate_rate(T_wR, T_wI, T_channelR, T_channelI, tAR.to(device), tAI.to(device)))\n",
        "\n",
        "                # Average over all mini-batches\n",
        "                RATE_Predicted_HBF = sum(R_predicted_HBF) / len(R_predicted_HBF)\n",
        "                RATE_Optimum_HBF = sum(R_optimum_HBF) / len(R_optimum_HBF)\n",
        "                RATE_Ratie_HBF = 100 * RATE_Predicted_HBF / RATE_Optimum_HBF\n",
        "                #m6y line\n",
        "                RATE_Predicted_HBF1.append(RATE_Predicted_HBF)\n",
        "                RATE_Optimum_HBF1.append(RATE_Optimum_HBF)\n",
        "                scheduler_MT.step(RATE_Predicted_HBF)\n",
        "               \n",
        "                print('Iter:==>{:3d} Loss_Class:{:.3f} Rate_opt_HBF:{:.2f} Rate_pre_HBF:{:.2f} Ratio_HBF:{:.2f}%'.\n",
        "                    format(i, loss_clas, RATE_Optimum_HBF, RATE_Predicted_HBF, RATE_Ratie_HBF))\n",
        "                \n",
        "else:\n",
        "    raise Exception('BF_approach is wrong !!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Inputs_MT.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-ztM9BahmYz",
        "outputId": "2fef7d9f-0b14-4975-d428-497a41263e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([500, 1, 4, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCQViR0lk5PU",
        "outputId": "76d2c9f3-7951-4eb3-cc5f-8c31b00782f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our model: \n",
            "\n",
            " Net_m_task_CNN(\n",
            "  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu1): LeakyReLU(negative_slope=0.01)\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (do1): Dropout2d(p=0.05, inplace=False)\n",
            "  (cnn2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): LeakyReLU(negative_slope=0.01)\n",
            "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (do2): Dropout2d(p=0.05, inplace=False)\n",
            "  (cnn3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu3): LeakyReLU(negative_slope=0.01)\n",
            "  (bn3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (do3): Dropout2d(p=0.05, inplace=False)\n",
            "  (lstm1): LSTM(1024, 512, batch_first=True, bidirectional=True)\n",
            "  (do4): Dropout(p=0.05, inplace=False)\n",
            "  (lstm2): LSTM(1024, 128, batch_first=True, bidirectional=True)\n",
            "  (do5): Dropout(p=0.05, inplace=False)\n",
            "  (fc20): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (bn20): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu20): LeakyReLU(negative_slope=0.01)\n",
            "  (do20): Dropout(p=0.05, inplace=False)\n",
            "  (fc30): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (bn30): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu30): LeakyReLU(negative_slope=0.01)\n",
            "  (do30): Dropout(p=0.05, inplace=False)\n",
            "  (fc7R): Linear(in_features=1024, out_features=32, bias=True)\n",
            "  (fc8R): Linear(in_features=1024, out_features=32, bias=True)\n",
            "  (fc9C): Linear(in_features=1024, out_features=5, bias=True)\n",
            ") \n",
            "\n",
            "The state dict keys: \n",
            "\n",
            " odict_keys(['cnn1.weight', 'cnn1.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'cnn2.weight', 'cnn2.bias', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'cnn3.weight', 'cnn3.bias', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var', 'bn3.num_batches_tracked', 'lstm1.weight_ih_l0', 'lstm1.weight_hh_l0', 'lstm1.bias_ih_l0', 'lstm1.bias_hh_l0', 'lstm1.weight_ih_l0_reverse', 'lstm1.weight_hh_l0_reverse', 'lstm1.bias_ih_l0_reverse', 'lstm1.bias_hh_l0_reverse', 'lstm2.weight_ih_l0', 'lstm2.weight_hh_l0', 'lstm2.bias_ih_l0', 'lstm2.bias_hh_l0', 'lstm2.weight_ih_l0_reverse', 'lstm2.weight_hh_l0_reverse', 'lstm2.bias_ih_l0_reverse', 'lstm2.bias_hh_l0_reverse', 'fc20.weight', 'fc20.bias', 'bn20.weight', 'bn20.bias', 'bn20.running_mean', 'bn20.running_var', 'bn20.num_batches_tracked', 'fc30.weight', 'fc30.bias', 'bn30.weight', 'bn30.bias', 'bn30.running_mean', 'bn30.running_var', 'bn30.num_batches_tracked', 'fc7R.weight', 'fc7R.bias', 'fc8R.weight', 'fc8R.bias', 'fc9C.weight', 'fc9C.bias'])\n"
          ]
        }
      ],
      "source": [
        "print(\"Our model: \\n\\n\", Model_m_task, '\\n')\n",
        "print(\"The state dict keys: \\n\\n\", Model_m_task.state_dict().keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUdTnhGhlnM0"
      },
      "outputs": [],
      "source": [
        "torch.save(Model_m_task.state_dict(), 'checkpoint.pth')\n",
        "\n",
        "# download checkpoint file\n",
        "#files.download('checkpoint.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFxuSK4zl_S9",
        "outputId": "49484873-6531-4d9a-ad35-c18103185b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['cnn1.weight', 'cnn1.bias', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'cnn2.weight', 'cnn2.bias', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'cnn3.weight', 'cnn3.bias', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var', 'bn3.num_batches_tracked', 'lstm1.weight_ih_l0', 'lstm1.weight_hh_l0', 'lstm1.bias_ih_l0', 'lstm1.bias_hh_l0', 'lstm1.weight_ih_l0_reverse', 'lstm1.weight_hh_l0_reverse', 'lstm1.bias_ih_l0_reverse', 'lstm1.bias_hh_l0_reverse', 'lstm2.weight_ih_l0', 'lstm2.weight_hh_l0', 'lstm2.bias_ih_l0', 'lstm2.bias_hh_l0', 'lstm2.weight_ih_l0_reverse', 'lstm2.weight_hh_l0_reverse', 'lstm2.bias_ih_l0_reverse', 'lstm2.bias_hh_l0_reverse', 'fc20.weight', 'fc20.bias', 'bn20.weight', 'bn20.bias', 'bn20.running_mean', 'bn20.running_var', 'bn20.num_batches_tracked', 'fc30.weight', 'fc30.bias', 'bn30.weight', 'bn30.bias', 'bn30.running_mean', 'bn30.running_var', 'bn30.num_batches_tracked', 'fc7R.weight', 'fc7R.bias', 'fc8R.weight', 'fc8R.bias', 'fc9C.weight', 'fc9C.bias'])\n"
          ]
        }
      ],
      "source": [
        "state_dict = torch.load('checkpoint.pth')\n",
        "print(state_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCLg718VmThy",
        "outputId": "61319648-3c08-4780-939e-4d29a3f59808"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Model_m_task.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ajC7kfm0h4s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x=np.load('/content/drive/MyDrive/HBF-Net-main/DataBase_pro_channel_BS32_2p4GHz_1Path.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "r2rl_xULO_YN",
        "outputId": "e2cb1a46-be5a-427b-8a27-6c3cd9918e3c"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-f974d7fa538e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_clas1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#sampleTensor = torch.tensor(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#a=data.detach().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#a=np.asarray(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# Wrap Numpy array again in a suitable tensor when done, to support e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
          ]
        }
      ],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "data = out_clas1\n",
        "#sampleTensor = torch.tensor(data)\n",
        "a = np.array(data, dtype=np.float32)\n",
        "#a=data.detach().numpy()\n",
        "#a=np.asarray(data)\n",
        "print(data)\n",
        "#print(type(tf.Session().run(tf.SparseTensor(data))))\n",
        "\n",
        "#file_path = '/content/drive/MyDrive/mimo/data.mat'\n",
        "#scipy.io.savemat(file_path, {'data': data})\n",
        "#RATE_Predicted_HBF1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjE5sHdrofJG"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "x= w_prer\n",
        "y= w_prei\n",
        "a=x.detach().numpy()\n",
        "b=y.detach().numpy()\n",
        "#print(a)\n",
        "file_path = '/content/drive/MyDrive/HBF-Net-main/newres/fdp32wr1.mat'\n",
        "scipy.io.savemat(file_path, {'data': a})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUEkcN-7zWuR"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/HBF-Net-main/newres/fdp32wi1.mat'\n",
        "scipy.io.savemat(file_path, {'data': b})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0as1WEYHVoS"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "x=  An_Predr\n",
        "y=  An_Predi\n",
        "a=x.detach().numpy()\n",
        "b=y.detach().numpy()\n",
        "#print(a)\n",
        "file_path = '/content/drive/MyDrive/HBF-Net-main/newres/fdp32anprer.mat'\n",
        "scipy.io.savemat(file_path, {'data': a})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_3qDzFKILWR"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/HBF-Net-main/newres/fdp32anprei.mat'\n",
        "scipy.io.savemat(file_path, {'data': b})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-MxztZxIWud"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "x=  T_channelR \n",
        "y=  T_channelI\n",
        "a=x.detach().numpy()\n",
        "b=y.detach().numpy()\n",
        "#print(a)\n",
        "file_path = '/content/drive/MyDrive/HBF-Net-main/newres/fdp32tcnlr.mat'\n",
        "scipy.io.savemat(file_path, {'data': a})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4VB_K7aIgYN"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/HBF-Net-main/newres/fdp32tcnli.mat'\n",
        "scipy.io.savemat(file_path, {'data': b})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "BDDO7Rm4R8uK",
        "outputId": "a63c58c9-a351-4105-b1d4-8d59d873989c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-620890d5132b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#RATE_Predicted_HBF1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/HBF-Net-main/newres/fdp32pre.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRATE_Predicted_HBF1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#array_nor2_rpre_npy = np.load(\"/content/drive/MyDrive/HBF-Net-main/newres/orpre.npy\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RATE_Predicted_HBF1' is not defined"
          ]
        }
      ],
      "source": [
        "#RATE_Predicted_HBF1\n",
        "import numpy as np\n",
        "np.save(\"/content/drive/MyDrive/HBF-Net-main/newres/fdp32pre.npy\", RATE_Predicted_HBF1)\n",
        "\n",
        "#array_nor2_rpre_npy = np.load(\"/content/drive/MyDrive/HBF-Net-main/newres/orpre.npy\")\n",
        "\n",
        "#print(array_nor2_rpre_npy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD03A8rfj852"
      },
      "outputs": [],
      "source": [
        "#RATE_Optimum_HBF1\n",
        "np.save(\"/content/drive/MyDrive/HBF-Net-main/newres/fdp32op.npy\", RATE_Optimum_HBF1)\n",
        "\n",
        "#array_nor2_rop_npy = np.load(\"orop.npy\")\n",
        "\n",
        "#print(array_nor2_rop_npy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odu2WBAXDWXA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdF9Ef8FkOKI"
      },
      "outputs": [],
      "source": [
        "#loss_clas1\n",
        "losses= [ loss.detach().numpy() for loss in loss_clas1]\n",
        "ab=np.array(losses)\n",
        "np.save(\"/content/drive/MyDrive/HBF-Net-main/newres/fdp32loss.npy\", ab)\n",
        "\n",
        "#array_nor2_rloss_npy = np.load(\"135db32loss.npy\")\n",
        "\n",
        "#print(array_nor2_rloss_npy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DChj_8ZEhs8_"
      },
      "outputs": [],
      "source": [
        "nor2_rpre = np.load(\"nor2_rpre.npy\")\n",
        "nor2_rloss = np.load(\"nor2_r_loss.npy\")\n",
        "nor2_rop = np.load(\"nor2_r_op.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AN63DoZJhiXK",
        "outputId": "dfad2069-855b-40ce-93b8-827aa564f0fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.2779629 2.552107  3.1446579 3.5213933 3.756641  3.9131176 4.0276055\n",
            " 4.1140146 4.1827497 4.238386  4.2831883 4.320556  4.352273  4.3798323\n",
            " 4.4040103 4.425377  4.443857  4.4603553 4.4757757 4.4896193 4.50748\n",
            " 4.526102  4.54169   4.558505  4.575614  4.592451  4.6089864 4.6240835\n",
            " 4.638486  4.652303  4.6652455 4.6762586 4.6871567 4.6978393 4.708487\n",
            " 4.718245  4.727765  4.736401  4.7448983 4.7522507 4.759458  4.766545\n",
            " 4.7734904 4.7798543 4.785656  4.791723  4.7975307 4.8032403 4.8088007\n",
            " 4.8139663 4.8191004 4.8240895 4.8290095 4.8337765 4.8382206 4.8425016\n",
            " 4.846633  4.8504176 4.8538218 4.8574567 4.860896  4.8645177 4.867785\n",
            " 4.8707786 4.8739634 4.877034  4.880181  4.88311   4.88593   4.8887777\n",
            " 4.891427  4.894009  4.89623   4.898732  4.9012065 4.903707  4.9061313\n",
            " 4.9084134 4.910402  4.912624  4.914635  4.9166083 4.9186616 4.920652\n",
            " 4.922512  4.924387  4.9263024 4.927975  4.9298444 4.931545  4.9332337\n",
            " 4.9348874 4.9365354 4.938116  4.9397326 4.941304  4.9426017 4.9438257\n",
            " 4.9453077 4.946849  4.9481525 4.949448  4.9507246 4.9519277 4.9530597\n",
            " 4.9542894 4.955534  4.956794  4.9580393 4.959282  4.960483  4.961695\n",
            " 4.9628534 4.96395   4.96498   4.9660945 4.9671946 4.968193  4.969285\n",
            " 4.970319  4.9713583 4.972405  4.9733396 4.974189  4.975142  4.9760885\n",
            " 4.976968  4.9778676 4.9787664 4.9796915 4.980473  4.9805737 4.9812355\n",
            " 4.9819884 4.982794  4.9835763 4.98439   4.9851804 4.985898  4.9866967\n",
            " 4.9875264 4.988315  4.989135  4.989967  4.9906325 4.9913225 4.991999\n",
            " 4.9927425 4.9934545 4.994117  4.994784  4.9954944 4.9961853 4.9968996\n",
            " 4.997562  4.9980655 4.9987597 4.9994397 5.0000725 5.0006647 5.001289\n",
            " 5.001825  5.002445  5.003029  5.003551  5.0041065 5.0045767 5.005196\n",
            " 5.005777  5.0063295 5.0068665 5.0073857 5.0079103 5.00848   5.009\n",
            " 5.009515  5.0100327 5.0105424 5.011     5.0115294 5.0120163 5.0125313\n",
            " 5.0130587 5.0135627 5.0140586 5.014539  5.015031  5.015514  5.015969\n",
            " 5.0164003 5.016775  5.017169  5.0175943 5.018048  5.0184913 5.018917\n",
            " 5.0193515 5.0197477 5.0201063 5.020451  5.020833  5.021137  5.0214458\n",
            " 5.0218387 5.022184  5.0225406 5.0229287 5.0232587 5.0236354 5.023915\n",
            " 5.0242667 5.0246367 5.025024  5.0252647 5.0255384 5.0258718 5.026194\n",
            " 5.026546  5.0268574 5.027177  5.0275273 5.0277934 5.0281267 5.028394\n",
            " 5.0286517 5.02896   5.029308  5.029642  5.029957  5.0302606 5.0305805\n",
            " 5.030891  5.0311985 5.031516  5.0318537 5.032168  5.032476  5.032768\n",
            " 5.033071  5.033387  5.033695  5.033999  5.034314  5.0346136 5.0349283\n",
            " 5.0352273 5.0355167 5.035771  5.0360456 5.036336  5.0366073 5.0368714\n",
            " 5.0371203 5.037397  5.0376353 5.0378327 5.037985  5.038175  5.038384\n",
            " 5.0385556 5.0387497 5.03891   5.0390716 5.0391984 5.0393634 5.039538\n",
            " 5.039749  5.03996   5.040158  5.040361  5.0405912 5.0408173 5.0410576\n",
            " 5.041292  5.0415196 5.04173   5.04194   5.0421524 5.042365  5.0425844\n",
            " 5.0427723 5.042943  5.043119  5.043327  5.0435543 5.043742  5.0439525\n",
            " 5.044144  5.0443406 5.0445247 5.0447397 5.0449505 5.045168  5.0453644\n",
            " 5.045549  5.045754  5.0459538 5.0461397 5.046315  5.0465074 5.0467014\n",
            " 5.046898  5.047073  5.047242  5.047403  5.047556  5.047742  5.047921\n",
            " 5.048101  5.0482697 5.048455  5.048636  5.0488033 5.0489936 5.0491824\n",
            " 5.0493784 5.049529  5.0496917 5.0498586 5.0500226 5.050194  5.050384\n",
            " 5.050571  5.0507493 5.050899  5.0510654 5.0512247 5.0513883 5.0515633\n",
            " 5.051719  5.0518823 5.052018  5.0521393 5.0523086 5.052471  5.0526195\n",
            " 5.0527773 5.052933  5.0530686 5.0532193 5.0533514 5.0534835 5.053644\n",
            " 5.0537767 5.053931  5.0540833 5.0542345 5.0543857 5.0545425 5.054691\n",
            " 5.0548506 5.055001  5.055123  5.055253  5.055352  5.0554805 5.0556226\n",
            " 5.055761  5.055918  5.0560665 5.056219  5.0563703 5.0564857 5.05662\n",
            " 5.0567408 5.0568337 5.0569606 5.057069  5.05719   5.0573363 5.0574765\n",
            " 5.057618  5.0577493 5.0578904 5.0580363 5.0581784 5.0583024 5.058443\n",
            " 5.0585647 5.0586877 5.058812  5.058955  5.059098  5.05924   5.0593605\n",
            " 5.059484  5.0596237 5.059747  5.0598664 5.0599723 5.060094  5.060206\n",
            " 5.0603065 5.0604224 5.060534  5.060638  5.060751  5.0608697 5.0609775\n",
            " 5.061091  5.0612    5.0613046 5.061411  5.061509  5.061596  5.061654\n",
            " 5.0617366 5.06183   5.061919  5.062017  5.062103  5.0621877 5.0622835\n",
            " 5.0623584 5.062433  5.062485  5.062534  5.062593  5.0626683 5.0627475\n",
            " 5.0628386 5.0629287 5.0630217 5.063111  5.0631986 5.063288  5.0633826\n",
            " 5.0634785 5.0635695 5.0636644 5.063755  5.0638456 5.0639315 5.0640206\n",
            " 5.0641117 5.0642037 5.064296  5.0643907 5.0644846 5.064574  5.0646625\n",
            " 5.064752  5.064839  5.064927  5.0650153 5.0651107 5.065204  5.0653014\n",
            " 5.0653973 5.0654926 5.0655875 5.065682  5.065774  5.0658684 5.0659657\n",
            " 5.066048  5.066131  5.066228  5.066326  5.066422  5.0665193 5.066615\n",
            " 5.066707  5.0668    5.0668907 5.0669785 5.0670714 5.0671606 5.06725\n",
            " 5.067342  5.0674295 5.0675197 5.067612  5.067705  5.0677986 5.067886\n",
            " 5.0679708 5.0680566 5.068142  5.068234  5.0683265 5.0684185 5.0685105\n",
            " 5.0685997 5.068688  5.068776  5.0688677 5.0689564 5.0690455 5.069135\n",
            " 5.0692244 5.0693135 5.069402  5.06949   5.0695777 5.069665  5.06975\n",
            " 5.0698323 5.0699196]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "#losses= [ loss.detach().numpy() for loss in loss_clas1]\n",
        "ab=np.array(nor2_rpre)\n",
        "#abc=np.abs(ab)\n",
        "print(ab)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "with torch.no_grad():\n",
        "  plt.plot(ab)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "cso5polXq2Uy",
        "outputId": "0e942b75-f6f1-4aa3-8cb4-fba328c97cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.3580796 -1.7793244 -2.0807128 ... -5.132564  -5.111367  -5.10725  ]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#ab=loss_clas1.numpy()\n",
        "#print(ab)\n",
        "\n",
        "import numpy as np\n",
        "#losses= [ loss.detach().numpy() for loss in nor2_rloss]\n",
        "ab=np.array(nor2_rloss)\n",
        "#abc=np.abs(ab)\n",
        "print(ab)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "with torch.no_grad():\n",
        "  plt.plot(ab)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C2wKBVhhlKat",
        "outputId": "81f9d7e4-d79f-4b37-f07c-d9ec78f08954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.         0.33601233 0.4922775  0.5916287  0.6536673  0.6949327\n",
            " 0.725125   0.74791247 0.766039   0.78071123 0.7925263  0.8023808\n",
            " 0.81074506 0.8180129  0.824389   0.8300237  0.8348973  0.83924806\n",
            " 0.8433147  0.8469655  0.8516757  0.8565866  0.8606973  0.86513174\n",
            " 0.8696436  0.8740839  0.8784445  0.88242584 0.886224   0.88986784\n",
            " 0.8932809  0.8961853  0.89905924 0.90187645 0.9046844  0.90725774\n",
            " 0.90976834 0.9120458  0.9142867  0.9162256  0.9181263  0.9199952\n",
            " 0.92182684 0.9235051  0.9250351  0.926635   0.9281666  0.92967236\n",
            " 0.93113875 0.932501   0.93385494 0.93517065 0.9364681  0.93772525\n",
            " 0.93889725 0.9400262  0.94111574 0.9421138  0.9430115  0.9439701\n",
            " 0.94487715 0.9458322  0.94669384 0.9474833  0.9483232  0.94913304\n",
            " 0.94996285 0.95073533 0.951479   0.95223    0.95292866 0.9536096\n",
            " 0.9541953  0.95485514 0.95550764 0.9561671  0.95680636 0.95740825\n",
            " 0.9579326  0.95851856 0.959049   0.95956933 0.96011084 0.9606357\n",
            " 0.96112627 0.9616207  0.96212584 0.962567   0.9630599  0.9635083\n",
            " 0.96395373 0.96438986 0.96482444 0.9652413  0.9656676  0.96608204\n",
            " 0.9664242  0.96674705 0.9671379  0.96754426 0.96788806 0.9682297\n",
            " 0.96856636 0.96888363 0.96918213 0.96950644 0.9698347  0.9701669\n",
            " 0.97049534 0.97082305 0.97113985 0.9714595  0.9717649  0.9720542\n",
            " 0.9723258  0.97261965 0.97290975 0.9731731  0.97346103 0.97373366\n",
            " 0.9740078  0.9742838  0.9745303  0.9747543  0.9750056  0.97525525\n",
            " 0.9754871  0.9757244  0.97596145 0.9762054  0.9764115  0.97643805\n",
            " 0.97661257 0.9768111  0.97702354 0.9772299  0.9774444  0.9776529\n",
            " 0.97784215 0.9780528  0.9782716  0.97847956 0.97869575 0.97891515\n",
            " 0.97909075 0.97927266 0.9794511  0.97964716 0.9798349  0.98000956\n",
            " 0.9801855  0.98037285 0.98055506 0.98074347 0.9809181  0.9810509\n",
            " 0.981234   0.9814133  0.9815802  0.98173636 0.981901   0.9820423\n",
            " 0.9822059  0.9823598  0.9824975  0.982644   0.982768   0.9829314\n",
            " 0.98308456 0.9832303  0.98337185 0.9835088  0.98364717 0.98379743\n",
            " 0.98393446 0.9840703  0.98420686 0.98434126 0.984462   0.98460156\n",
            " 0.98472995 0.9848658  0.98500484 0.98513776 0.98526853 0.9853952\n",
            " 0.98552495 0.9856523  0.9857723  0.9858861  0.985985   0.9860888\n",
            " 0.986201   0.98632056 0.9864375  0.9865498  0.98666435 0.9867689\n",
            " 0.98686343 0.98695433 0.98705506 0.9871353  0.98721665 0.9873203\n",
            " 0.9874113  0.9875054  0.9876078  0.98769474 0.9877941  0.9878678\n",
            " 0.9879606  0.9880582  0.9881603  0.9882238  0.988296   0.9883839\n",
            " 0.9884689  0.9885617  0.9886438  0.98872805 0.9888205  0.98889065\n",
            " 0.98897856 0.9890491  0.989117   0.9891984  0.98929006 0.98937815\n",
            " 0.9894612  0.9895413  0.98962563 0.9897075  0.98978865 0.9898724\n",
            " 0.9899614  0.9900443  0.99012554 0.9902025  0.9902824  0.9903658\n",
            " 0.99044704 0.99052715 0.9906103  0.9906892  0.99077225 0.9908511\n",
            " 0.9909274  0.99099445 0.9910669  0.99114347 0.991215   0.99128467\n",
            " 0.9913503  0.99142325 0.99148613 0.99153817 0.9915783  0.99162847\n",
            " 0.99168354 0.99172884 0.99178    0.99182224 0.99186486 0.99189836\n",
            " 0.9919418  0.9919879  0.99204355 0.99209917 0.9921513  0.9922049\n",
            " 0.99226564 0.99232525 0.9923886  0.9924505  0.9925105  0.99256593\n",
            " 0.99262136 0.99267733 0.9927334  0.9927913  0.9928408  0.9928858\n",
            " 0.99293226 0.9929871  0.99304706 0.9930966  0.9931521  0.9932026\n",
            " 0.9932544  0.99330294 0.9933597  0.99341524 0.9934726  0.9935244\n",
            " 0.99357307 0.99362713 0.9936798  0.9937289  0.9937751  0.9938258\n",
            " 0.993877   0.9939288  0.993975   0.9940196  0.99406195 0.99410236\n",
            " 0.9941514  0.9941987  0.99424607 0.9942906  0.9943395  0.99438715\n",
            " 0.9944313  0.9944815  0.9945313  0.99458295 0.9946227  0.99466556\n",
            " 0.9947096  0.9947528  0.994798   0.9948482  0.9948975  0.9949445\n",
            " 0.994984   0.99502784 0.99506986 0.995113   0.99515915 0.9952003\n",
            " 0.99524325 0.99527913 0.995311   0.99535567 0.9953986  0.9954377\n",
            " 0.9954793  0.9955204  0.9955561  0.9955959  0.9956307  0.99566555\n",
            " 0.9957079  0.99574286 0.9957836  0.99582374 0.9958636  0.99590343\n",
            " 0.9959448  0.99598396 0.99602604 0.9960657  0.99609786 0.9961322\n",
            " 0.99615836 0.99619216 0.99622965 0.9962661  0.9963076  0.9963467\n",
            " 0.99638695 0.9964268  0.9964573  0.99649274 0.9965245  0.99654907\n",
            " 0.9965825  0.99661106 0.996643   0.9966816  0.9967186  0.9967559\n",
            " 0.99679047 0.9968277  0.99686617 0.99690366 0.9969364  0.99697345\n",
            " 0.9970055  0.99703795 0.9970708  0.9971085  0.9971461  0.99718356\n",
            " 0.9972154  0.997248   0.9972848  0.9973174  0.99734885 0.99737674\n",
            " 0.9974088  0.9974384  0.9974649  0.9974955  0.99752486 0.9975523\n",
            " 0.9975821  0.9976134  0.9976418  0.9976717  0.9977006  0.9977281\n",
            " 0.9977561  0.99778205 0.99780494 0.99782026 0.997842   0.99786663\n",
            " 0.9978902  0.9979159  0.9979386  0.997961   0.99798626 0.998006\n",
            " 0.9980256  0.9980394  0.99805224 0.99806786 0.9980877  0.9981086\n",
            " 0.99813265 0.99815637 0.9981809  0.9982044  0.99822754 0.9982512\n",
            " 0.9982761  0.9983014  0.9983254  0.99835044 0.9983743  0.9983982\n",
            " 0.99842083 0.9984444  0.9984684  0.99849266 0.9985169  0.99854195\n",
            " 0.9985667  0.99859023 0.9986136  0.99863726 0.99866015 0.9986834\n",
            " 0.99870664 0.9987318  0.99875647 0.9987821  0.9988074  0.9988325\n",
            " 0.99885756 0.9988825  0.99890673 0.99893165 0.9989573  0.99897903\n",
            " 0.9990009  0.9990264  0.99905235 0.9990776  0.9991033  0.9991286\n",
            " 0.99915284 0.99917734 0.99920124 0.99922436 0.9992489  0.9992724\n",
            " 0.99929595 0.9993202  0.99934334 0.9993671  0.9993915  0.999416\n",
            " 0.99944067 0.9994637  0.9994861  0.9995087  0.9995312  0.99955547\n",
            " 0.99957985 0.99960417 0.9996284  0.9996519  0.9996752  0.99969846\n",
            " 0.9997226  0.99974597 0.9997695  0.9997931  0.99981666 0.9998402\n",
            " 0.99986356 0.9998867  0.9999098  0.9999328  0.99995524 0.999977\n",
            " 1.        ]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "x = nor2_rpre\n",
        "\n",
        "y = nor2_rop\n",
        "a=np.array(x)\n",
        "a1=np.max(a)\n",
        "b1=np.min(a)\n",
        "c=np.array(y)\n",
        "a12=np.max(c)\n",
        "b12=np.min(c)\n",
        "z1=(a-b1)/(a1-b1)\n",
        "z2=(a-b12)/(a12-b12)\n",
        "print(z1)\n",
        "#print(b)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "with torch.no_grad():\n",
        "  plt.plot(z1)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9f7wNmaFR-7z",
        "outputId": "1b7e7c5a-e0a8-4c1d-d8ec-645910c17389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.2779629 2.552107  3.1446579 3.5213933 3.756641  3.9131176 4.0276055\n",
            " 4.1140146 4.1827497 4.238386  4.2831883 4.320556  4.352273  4.3798323\n",
            " 4.4040103 4.425377  4.443857  4.4603553 4.4757757 4.4896193 4.50748\n",
            " 4.526102  4.54169   4.558505  4.575614  4.592451  4.6089864 4.6240835\n",
            " 4.638486  4.652303  4.6652455 4.6762586 4.6871567 4.6978393 4.708487\n",
            " 4.718245  4.727765  4.736401  4.7448983 4.7522507 4.759458  4.766545\n",
            " 4.7734904 4.7798543 4.785656  4.791723  4.7975307 4.8032403 4.8088007\n",
            " 4.8139663 4.8191004 4.8240895 4.8290095 4.8337765 4.8382206 4.8425016\n",
            " 4.846633  4.8504176 4.8538218 4.8574567 4.860896  4.8645177 4.867785\n",
            " 4.8707786 4.8739634 4.877034  4.880181  4.88311   4.88593   4.8887777\n",
            " 4.891427  4.894009  4.89623   4.898732  4.9012065 4.903707  4.9061313\n",
            " 4.9084134 4.910402  4.912624  4.914635  4.9166083 4.9186616 4.920652\n",
            " 4.922512  4.924387  4.9263024 4.927975  4.9298444 4.931545  4.9332337\n",
            " 4.9348874 4.9365354 4.938116  4.9397326 4.941304  4.9426017 4.9438257\n",
            " 4.9453077 4.946849  4.9481525 4.949448  4.9507246 4.9519277 4.9530597\n",
            " 4.9542894 4.955534  4.956794  4.9580393 4.959282  4.960483  4.961695\n",
            " 4.9628534 4.96395   4.96498   4.9660945 4.9671946 4.968193  4.969285\n",
            " 4.970319  4.9713583 4.972405  4.9733396 4.974189  4.975142  4.9760885\n",
            " 4.976968  4.9778676 4.9787664 4.9796915 4.980473  4.9805737 4.9812355\n",
            " 4.9819884 4.982794  4.9835763 4.98439   4.9851804 4.985898  4.9866967\n",
            " 4.9875264 4.988315  4.989135  4.989967  4.9906325 4.9913225 4.991999\n",
            " 4.9927425 4.9934545 4.994117  4.994784  4.9954944 4.9961853 4.9968996\n",
            " 4.997562  4.9980655 4.9987597 4.9994397 5.0000725 5.0006647 5.001289\n",
            " 5.001825  5.002445  5.003029  5.003551  5.0041065 5.0045767 5.005196\n",
            " 5.005777  5.0063295 5.0068665 5.0073857 5.0079103 5.00848   5.009\n",
            " 5.009515  5.0100327 5.0105424 5.011     5.0115294 5.0120163 5.0125313\n",
            " 5.0130587 5.0135627 5.0140586 5.014539  5.015031  5.015514  5.015969\n",
            " 5.0164003 5.016775  5.017169  5.0175943 5.018048  5.0184913 5.018917\n",
            " 5.0193515 5.0197477 5.0201063 5.020451  5.020833  5.021137  5.0214458\n",
            " 5.0218387 5.022184  5.0225406 5.0229287 5.0232587 5.0236354 5.023915\n",
            " 5.0242667 5.0246367 5.025024  5.0252647 5.0255384 5.0258718 5.026194\n",
            " 5.026546  5.0268574 5.027177  5.0275273 5.0277934 5.0281267 5.028394\n",
            " 5.0286517 5.02896   5.029308  5.029642  5.029957  5.0302606 5.0305805\n",
            " 5.030891  5.0311985 5.031516  5.0318537 5.032168  5.032476  5.032768\n",
            " 5.033071  5.033387  5.033695  5.033999  5.034314  5.0346136 5.0349283\n",
            " 5.0352273 5.0355167 5.035771  5.0360456 5.036336  5.0366073 5.0368714\n",
            " 5.0371203 5.037397  5.0376353 5.0378327 5.037985  5.038175  5.038384\n",
            " 5.0385556 5.0387497 5.03891   5.0390716 5.0391984 5.0393634 5.039538\n",
            " 5.039749  5.03996   5.040158  5.040361  5.0405912 5.0408173 5.0410576\n",
            " 5.041292  5.0415196 5.04173   5.04194   5.0421524 5.042365  5.0425844\n",
            " 5.0427723 5.042943  5.043119  5.043327  5.0435543 5.043742  5.0439525\n",
            " 5.044144  5.0443406 5.0445247 5.0447397 5.0449505 5.045168  5.0453644\n",
            " 5.045549  5.045754  5.0459538 5.0461397 5.046315  5.0465074 5.0467014\n",
            " 5.046898  5.047073  5.047242  5.047403  5.047556  5.047742  5.047921\n",
            " 5.048101  5.0482697 5.048455  5.048636  5.0488033 5.0489936 5.0491824\n",
            " 5.0493784 5.049529  5.0496917 5.0498586 5.0500226 5.050194  5.050384\n",
            " 5.050571  5.0507493 5.050899  5.0510654 5.0512247 5.0513883 5.0515633\n",
            " 5.051719  5.0518823 5.052018  5.0521393 5.0523086 5.052471  5.0526195\n",
            " 5.0527773 5.052933  5.0530686 5.0532193 5.0533514 5.0534835 5.053644\n",
            " 5.0537767 5.053931  5.0540833 5.0542345 5.0543857 5.0545425 5.054691\n",
            " 5.0548506 5.055001  5.055123  5.055253  5.055352  5.0554805 5.0556226\n",
            " 5.055761  5.055918  5.0560665 5.056219  5.0563703 5.0564857 5.05662\n",
            " 5.0567408 5.0568337 5.0569606 5.057069  5.05719   5.0573363 5.0574765\n",
            " 5.057618  5.0577493 5.0578904 5.0580363 5.0581784 5.0583024 5.058443\n",
            " 5.0585647 5.0586877 5.058812  5.058955  5.059098  5.05924   5.0593605\n",
            " 5.059484  5.0596237 5.059747  5.0598664 5.0599723 5.060094  5.060206\n",
            " 5.0603065 5.0604224 5.060534  5.060638  5.060751  5.0608697 5.0609775\n",
            " 5.061091  5.0612    5.0613046 5.061411  5.061509  5.061596  5.061654\n",
            " 5.0617366 5.06183   5.061919  5.062017  5.062103  5.0621877 5.0622835\n",
            " 5.0623584 5.062433  5.062485  5.062534  5.062593  5.0626683 5.0627475\n",
            " 5.0628386 5.0629287 5.0630217 5.063111  5.0631986 5.063288  5.0633826\n",
            " 5.0634785 5.0635695 5.0636644 5.063755  5.0638456 5.0639315 5.0640206\n",
            " 5.0641117 5.0642037 5.064296  5.0643907 5.0644846 5.064574  5.0646625\n",
            " 5.064752  5.064839  5.064927  5.0650153 5.0651107 5.065204  5.0653014\n",
            " 5.0653973 5.0654926 5.0655875 5.065682  5.065774  5.0658684 5.0659657\n",
            " 5.066048  5.066131  5.066228  5.066326  5.066422  5.0665193 5.066615\n",
            " 5.066707  5.0668    5.0668907 5.0669785 5.0670714 5.0671606 5.06725\n",
            " 5.067342  5.0674295 5.0675197 5.067612  5.067705  5.0677986 5.067886\n",
            " 5.0679708 5.0680566 5.068142  5.068234  5.0683265 5.0684185 5.0685105\n",
            " 5.0685997 5.068688  5.068776  5.0688677 5.0689564 5.0690455 5.069135\n",
            " 5.0692244 5.0693135 5.069402  5.06949   5.0695777 5.069665  5.06975\n",
            " 5.0698323 5.0699196]\n",
            "[5.2997866 5.2997866 5.2997866 5.2997866 5.2997866 5.2997866 5.299786\n",
            " 5.2997866 5.299787  5.299787  5.2997875 5.2997875 5.299787  5.2997866\n",
            " 5.2997866 5.299786  5.2997856 5.2997856 5.2997856 5.299785  5.299785\n",
            " 5.299785  5.2997847 5.2997847 5.299785  5.299785  5.2997856 5.2997856\n",
            " 5.2997856 5.299786  5.299786  5.299786  5.299786  5.299786  5.2997866\n",
            " 5.2997866 5.2997866 5.2997866 5.2997866 5.2997866 5.299787  5.299787\n",
            " 5.299787  5.299787  5.299787  5.299787  5.299787  5.299787  5.299787\n",
            " 5.299787  5.2997866 5.2997866 5.299786  5.299786  5.2997856 5.2997856\n",
            " 5.2997856 5.299785  5.299785  5.2997847 5.2997847 5.2997847 5.299784\n",
            " 5.299784  5.299784  5.2997837 5.2997837 5.2997837 5.299783  5.299783\n",
            " 5.299783  5.299783  5.2997828 5.2997828 5.2997828 5.2997828 5.2997823\n",
            " 5.2997823 5.2997823 5.2997823 5.2997823 5.299782  5.299782  5.299782\n",
            " 5.299782  5.299782  5.2997813 5.2997813 5.2997813 5.2997813 5.2997813\n",
            " 5.2997813 5.299781  5.299781  5.299781  5.299781  5.299781  5.299781\n",
            " 5.2997813 5.2997813 5.299782  5.299782  5.2997823 5.2997823 5.2997828\n",
            " 5.2997828 5.299783  5.299783  5.299783  5.2997837 5.2997837 5.299784\n",
            " 5.299784  5.299784  5.2997847 5.2997847 5.2997847 5.299785  5.299785\n",
            " 5.299785  5.2997856 5.2997856 5.2997856 5.299786  5.299786  5.299786\n",
            " 5.2997866 5.2997866 5.2997866 5.299787  5.299787  5.299787  5.299787\n",
            " 5.2997875 5.2997875 5.2997875 5.2997875 5.299788  5.299788  5.299788\n",
            " 5.2997885 5.2997885 5.2997885 5.2997885 5.2997885 5.299789  5.299789\n",
            " 5.299789  5.299789  5.2997894 5.2997894 5.2997894 5.2997894 5.2997894\n",
            " 5.29979   5.29979   5.29979   5.29979   5.29979   5.2997904 5.2997904\n",
            " 5.2997904 5.2997904 5.2997904 5.299791  5.299791  5.299791  5.299791\n",
            " 5.299791  5.299791  5.2997913 5.2997913 5.2997913 5.2997913 5.2997913\n",
            " 5.2997913 5.299792  5.299792  5.299792  5.299792  5.299792  5.299792\n",
            " 5.299792  5.2997923 5.2997923 5.2997923 5.2997923 5.2997923 5.2997923\n",
            " 5.2997923 5.299793  5.299793  5.299793  5.299793  5.299793  5.299793\n",
            " 5.299793  5.299793  5.2997932 5.2997932 5.2997932 5.2997932 5.2997932\n",
            " 5.2997932 5.2997932 5.2997932 5.2997937 5.2997937 5.2997937 5.2997937\n",
            " 5.2997937 5.2997937 5.2997937 5.2997937 5.2997937 5.2997937 5.299794\n",
            " 5.299794  5.299794  5.299794  5.299794  5.299794  5.299794  5.299794\n",
            " 5.299794  5.299794  5.2997947 5.2997947 5.2997947 5.2997947 5.2997947\n",
            " 5.2997947 5.2997947 5.2997947 5.2997947 5.2997947 5.2997947 5.299795\n",
            " 5.299795  5.299795  5.299795  5.299795  5.299795  5.299795  5.299795\n",
            " 5.299795  5.299795  5.299795  5.299795  5.2997956 5.2997956 5.2997956\n",
            " 5.2997956 5.2997956 5.2997956 5.2997956 5.2997956 5.2997956 5.2997956\n",
            " 5.2997956 5.2997956 5.2997956 5.299796  5.299796  5.299796  5.299796\n",
            " 5.299796  5.299796  5.299796  5.299796  5.299796  5.299796  5.299796\n",
            " 5.299796  5.299796  5.299796  5.299796  5.2997966 5.2997966 5.2997966\n",
            " 5.2997966 5.2997966 5.2997966 5.2997966 5.2997966 5.2997966 5.2997966\n",
            " 5.2997966 5.2997966 5.2997966 5.2997966 5.2997966 5.2997966 5.2997966\n",
            " 5.299797  5.299797  5.299797  5.299797  5.299797  5.299797  5.299797\n",
            " 5.299797  5.299797  5.299797  5.299797  5.299797  5.299797  5.299797\n",
            " 5.299797  5.299797  5.299797  5.299797  5.299797  5.2997975 5.2997975\n",
            " 5.2997975 5.2997975 5.2997975 5.2997975 5.2997975 5.2997975 5.2997975\n",
            " 5.2997975 5.2997975 5.2997975 5.2997975 5.2997975 5.2997975 5.2997975\n",
            " 5.2997975 5.2997975 5.2997975 5.2997975 5.2997975 5.2997975 5.299798\n",
            " 5.299798  5.299798  5.299798  5.299798  5.299798  5.299798  5.299798\n",
            " 5.299798  5.299798  5.299798  5.299798  5.299798  5.299798  5.299798\n",
            " 5.299798  5.299798  5.299798  5.299798  5.299798  5.299798  5.299798\n",
            " 5.299798  5.299798  5.299798  5.2997985 5.2997985 5.2997985 5.2997985\n",
            " 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985\n",
            " 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985\n",
            " 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985\n",
            " 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985\n",
            " 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985\n",
            " 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985 5.2997985\n",
            " 5.2997985 5.2997985 5.2997985 5.299799  5.299799  5.299799  5.299799\n",
            " 5.299799  5.299799  5.299799  5.299799  5.299799  5.299799  5.299799\n",
            " 5.299799  5.299799  5.299799  5.299799  5.299799  5.299799  5.299799\n",
            " 5.299799  5.299799  5.299799  5.299799  5.299799  5.299799  5.299799\n",
            " 5.299799  5.299799  5.299799  5.299799  5.299799  5.299799  5.299799\n",
            " 5.299799  5.299799  5.299799  5.299799  5.2997994 5.2997994 5.2997994\n",
            " 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994\n",
            " 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994\n",
            " 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994\n",
            " 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994\n",
            " 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994 5.2997994\n",
            " 5.2997994 5.2997994 5.2997994 5.2997994 5.2998    5.2998    5.2998\n",
            " 5.2998    5.2998    5.2998    5.2998    5.2998    5.2998    5.2998\n",
            " 5.2998    5.2998   ]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAarklEQVR4nO3de5Cb9X3v8fdXWu3F99vaGN8WYnIBCgY2xhSmB8hJhgAH2gmZQtMEUjJu0jAhnZzJlJwOnTDpTPNPSHM5oS70QBJayIWkLgkncQOckDKBrK+ADWRJTGxDvOvLetde766k53v+eB5pJa3WK68li0f6vGY0ei4/Pfo+Rnz880+/R4+5OyIiEn+JehcgIiLVoUAXEWkQCnQRkQahQBcRaRAKdBGRBtFSrzdetGiRd3V11evtRURiafPmzQfcvbPcvroFeldXFz09PfV6exGRWDKz1yfbpyEXEZEGoUAXEWkQCnQRkQahQBcRaRAKdBGRBqFAFxFpEAp0EZEGUbd56CLS3NydwCEbOIHnHtF6tC3rjhe0cSffLlwfXw4CStqE+4raTHaMgCnblz6XrSH/+sL9ROcz3r67awF/9Pay1wadEgW6SA0EgZMOAtJZJ50J8suZbEA6G23Pjm/LBmF4ZQInmw2Xs0G4HkTP2SAgGxA957ZFbbNRWy/YXvAofX2+bXb8GEEUPOUC1j1XUxhY423CkBoPYaIQzrWJjpk7XhScuaBuVh//b2+rX6Cb2W5gCMgCGXfvLtlvwD8C1wLDwG3uvqW6pUqzcnfGsgEj6YDRTDYfkpkgYCzjZILSkBxfzmTD12bK7gsYKwzZIHfc8DW55cLXTXhNwXHz7xWFYj0kDJIJI5kwWhIJEgYtyUS4zaLtyfHlwkfCLP/6hIWvTyYMK9iWMCOZIFyOtiVtfD1pRiK3P3oPM/LvZ4WvLzxe/lgl75c7phW+Z7hsVngcsKJ2ufUK2xfuz9cXtjFK2pyoBorPf3z/ePswLmvjZHroV7n7gUn2vR84J3pcCnwjepYG5+6MpAOGxzIMj2UZHstybCzD8Gi2aNvwWIZjo1mG0+G+4+kso5mAkXSWkWh5NJ1lJB0wkskyGj3n9tWqN9eaTJBKGi3JBKloOZVM0JK0aF+4nEomaE8lSLW30JJI0NoSBl4qWbxc+PrC9eJ9CVqT0WtaErTkA7g4YMNAhWQiEQZiMmwThm24ng/pxHhgSvOq1pDLjcA3Pbyf3S/NbJ6ZLXX3N6t0fKkBd+d4OsvQSIahkTRHjofPg9H60EiGwePRc7Q+NJJmsKDdsbHMSYVta0uCGa1JOlJJ2lNJ2loS+ed5M1ppTyVoa0nSngq3l7ZpSyVpnSQky4VnKhkGZmsUnKmWBKlEuF8BKI2m0kB34Kdm5sA/ufuGkv3LgD0F63ujbUWBbmbrgfUAK1eunFbBUp67MzSaoW9whL7BUfqPjnL42BiHhtMcOjbK4WNpDh0b4/DwGEMjGY6OZjg2miEzxdBAMmHMbm9hTnsq/7xq4QxmR+uz21voaE0ys7WFGa1JZrS2MKMtyYxUkpltE7e1JDWxSqRWKg30K9x9n5ktBjaZ2cvu/vOTfbPoL4INAN3d3U38lcjJGUln2TdwnDcGjtM3OMr+oSi0h0bZPzhC39AofUMjjKSDCa81g3kdKebPbGXBjFaWz5/B3I4UM9vCwM0HdUcusHPbUszpaKEjlVQvViQmKgp0d98XPfeZ2Q+AtUBhoO8DVhSsL4+2SQXcnQNHx+jtO8pvDxxjz+Fh9h4+zt7ouX9odMJrZrW1sHh2G4vntLFmxbz88pI57XTObqNzVhsLZrYytyOlXrFIk5gy0M1sJpBw96Fo+X3APSXNNgJ3mNkjhF+GHtH4eXkDw2O89MYgO98Y5NX9Q/T2H+W1vqMMjmTybVoSxpnzOlg+v4Or3tHJivkzWL6gg6VzO1gyp53Fs9uY2aYZpyJSrJJUWAL8IPpndwvwr+7+f83s4wDufh/wY8Ipi72E0xY/Wpty42UknWXH3iM8/9uDbN97hJ1vDLJv4Hh+/6JZbaxePJP/ceGZrF48i7d1zuLszpksndtBMqFhDhE5OVMGurv/BriwzPb7CpYd+GR1S4ufoZE0m18/zK92H+L53x5i+54jjGXDce2zO2dy8ar5fPiyVZx35hzOXTqHhbPa6lyxiDQS/bv9FLg7vX1H+c9dffxs1362/O4wgYczQ85fNpdb/3AVa89aSPeq+cyf2VrvckWkwSnQp+GNgeN8f/NeHtu6j98eOAbAuUvn8FdXrmbd2Qu5aOU8jXGLyGmn1KmQu/Psawf552d+w/97tR93WHf2Av7iirN4zzsXc+a8jnqXKCJNToE+hSBwfrrz93zj6dfYvvcInbPbuOOq1XzwkhWsXDij3uWJiOQp0CcRBM4Ptu7jfz/dy2v9x1i5YAZ//yfn84GLl9OeSta7PBGRCRToZWzbM8Df/fuLbN97hHctncNXbrmIa88/QxfoiMhbmgK9wLHRDF/40U4e+dUeFs1q48t/uoYb15ypS99FJBYU6JFXfj/EJx7ezO4Dx/jYFWfxqfecw+z2VL3LEhGpmAId+Pmr/Xz825uZ2dbCwx9bx2VvW1jvkkRETlrTB/oPt+7jf353O+csmc2DH303S+a017skEZFpaepAv/+Z3/CFH+1i3dkL2PCRbuZoiEVEYqxpA/07PXv4wo928f7zz+DeP12jqYgiEntNGejPvnaAzz32AlesXsRXbrmIlKYjikgDaLok6xsc4Y5/3UrXopl8/UMXK8xFpGE0VQ89CJzPfHc7w2MZvvOX65jboTFzEWkcTdU9ffDZ3Tzz6wP87XXnsnrx7HqXIyJSVU0T6LveHOQfnniZ//6uxXzo0pX1LkdEpOoqDnQzS5rZVjN7vMy+28ys38y2RY+PVbfMUzOSzvLpR7YxpyPFFz9wgS7lF5GGdDJj6HcCu4A5k+x/1N3vOPWSqu9Lm17llf1D/J+Pvlu3fRORhlVRD93MlgPXAffXtpzq+6/eA/zzM7/hzy5dyVXvWFzvckREaqbSIZcvA58FghO0+YCZ7TCz75nZinINzGy9mfWYWU9/f//J1nrS+oZGuPORbbytcxZ/e927av5+IiL1NGWgm9n1QJ+7bz5Bs/8Autz9AmAT8FC5Ru6+wd273b27s7NzWgVXKgicv350G0dH03z9zy5mRmtTzdAUkSZUSQ/9cuAGM9sNPAJcbWbfLmzg7gfdfTRavR+4pKpVTsO3fvk6/9V7kLuvP493nKEpiiLS+KYMdHe/y92Xu3sXcDPwpLv/eWEbM1tasHoD4ZendfPGwHH+4YmX+aO3d3LL2rKjPyIiDWfa4xBmdg/Q4+4bgU+Z2Q1ABjgE3Fad8qbnq0/2kgkC/v6Pz9cURRFpGicV6O7+NPB0tHx3wfa7gLuqWdh0/e7gMN/t2cOHLl3JigUz6l2OiMhp03BXij747G7M4K+uWl3vUkRETquGCvSRdJbHtu7lfeedoTsPiUjTaahA/8lLv2dgOM0t79ZvtYhI82moQN+47Q2WzevgD3WTZxFpQg0T6CPpLM++dpCr37mYREIzW0Sk+TRMoP9q9yGOp7Nc+Y7aXoEqIvJW1TCB/vQr/bQmE1ym4RYRaVINE+i/+PUB1p61QL/ZIiJNqyEC/ehohlf7hnh314J6lyIiUjcNEegv7D2CO1y4Ym69SxERqZuGCPQdewcAuGD5vDpXIiJSPw0R6K/sH2LJnDYWzGytdykiInXTEIH+6v4h3r5Ev3kuIs0t9oGeDZzevqMKdBFperEP9DcGjjOSDli9eFa9SxERqavYB/qeQ8MArNJvn4tIk4t9oL8eBfrKhQp0EWluFQe6mSXNbKuZPV5mX5uZPWpmvWb2nJl1VbPIE/ndoWFSSWPp3I7T9ZYiIm9JJ9NDv5PJb/58O3DY3VcD9wJfPNXCKvW7Q8Msm9dBUr+wKCJNrqJAN7PlwHXA/ZM0uRF4KFr+HvAeO013Z95/ZES9cxERKu+hfxn4LBBMsn8ZsAfA3TPAEWDCzx6a2Xoz6zGznv7+/mmUO9H+oRGWzGmryrFEROJsykA3s+uBPnfffKpv5u4b3L3b3bs7O0/9d8vdnf2Do7p/qIgIlfXQLwduMLPdwCPA1Wb27ZI2+4AVAGbWAswFDlaxzrIGhtOMZQIWK9BFRKYOdHe/y92Xu3sXcDPwpLv/eUmzjcCt0fJNURuvaqVl7B8aAdCQi4gIMO27QZjZPUCPu28EHgC+ZWa9wCHC4K+5vsFRABbPVg9dROSkAt3dnwaejpbvLtg+AnywmoVV4vDwGIB+ZVFEhJhfKXroWBjo82ek6lyJiEj9xTrQDw+nAZjboUAXEYl1oA8MjzG3I0VLMtanISJSFbFOwsPDaQ23iIhEYh3oA8NjzJuhL0RFRCDmgX7o2Jh66CIikVgH+sBwmvnqoYuIADEP9KGRNLPbp31tlIhIQ4ltoLs7w2NZZrYp0EVEIMaBPpoJyASuQBcRicQ20I+NZgCY2ZqscyUiIm8NsQ304bEsgHroIiKR2Ab60aiHPkuBLiICxDjQ80MuCnQRESDOgZ4fctEYuogIxDnQ1UMXESkS20A/mp/lokAXEYEKAt3M2s3seTPbbmYvmdnny7S5zcz6zWxb9PhYbcodd0xfioqIFKkkDUeBq939qJmlgF+Y2RPu/suSdo+6+x3VL7E8TVsUESk2ZRq6uwNHo9VU9PBaFlWJ42NZkgmjtSW2o0YiIlVVURqaWdLMtgF9wCZ3f65Msw+Y2Q4z+56ZrZjkOOvNrMfMevr7+0+hbBjNZGlTmIuI5FWUiO6edfc1wHJgrZmdX9LkP4Aud78A2AQ8NMlxNrh7t7t3d3Z2nkrdjGYCBbqISIGTSkR3HwCeAq4p2X7Q3Uej1fuBS6pT3uRG0wFtLZqDLiKSU8ksl04zmxctdwDvBV4uabO0YPUGYFc1iyxnNJOlLaUeuohITiVTRJYCD5lZkvAvgO+4++Nmdg/Q4+4bgU+Z2Q1ABjgE3FargnM05CIiUqySWS47gIvKbL+7YPku4K7qlnZiYaBryEVEJCe2XVzNchERKRbbRBxNBxpDFxEpENtE1JCLiEixGAe6hlxERArFNhE1y0VEpFhsE1EXFomIFItvoOvCIhGRIrFNRA25iIgUi20iapaLiEixWAZ6JhuQDVw9dBGRArFMxNFMAKAxdBGRArFMxHyga8hFRCQvpoEe3k9Ut58TERkXy0RMZ8JbmrYkrM6ViIi8dcQz0INwyEU9dBGRcbFMxEw210OPZfkiIjURy0RMZ8MeektSQy4iIjmV3FO03cyeN7PtZvaSmX2+TJs2M3vUzHrN7Dkz66pFsTmZIOyhpxToIiJ5lfTQR4Gr3f1CYA1wjZmtK2lzO3DY3VcD9wJfrG6ZxTK5HrqGXERE8qZMRA8djVZT0cNLmt0IPBQtfw94j5nVrPuczo2hq4cuIpJXURfXzJJmtg3oAza5+3MlTZYBewDcPQMcARaWOc56M+sxs57+/v5pF52JZrmkkuqhi4jkVJSI7p519zXAcmCtmZ0/nTdz9w3u3u3u3Z2dndM5BFA4y0U9dBGRnJPq4rr7APAUcE3Jrn3ACgAzawHmAgerUWA5uVku6qGLiIyrZJZLp5nNi5Y7gPcCL5c02wjcGi3fBDzp7qXj7FWTm+WiMXQRkXEtFbRZCjxkZknCvwC+4+6Pm9k9QI+7bwQeAL5lZr3AIeDmmlVMwTx0zXIREcmbMtDdfQdwUZntdxcsjwAfrG5pk8uNoWseuojIuFh2cTXLRURkolgmouahi4hMFMtAz10pmtIYuohIXiwTUbNcREQmimWgp/NfisayfBGRmohlIo7/OJd66CIiObEM9Nw89KQCXUQkL56BHjippFHDH3QUEYmdWAZ6JhvoKlERkRKxTMV01jXDRUSkRCwDPRMEmuEiIlIilqmYybpmuIiIlIhloKezrh66iEiJWKZiOOSiHrqISKF4BnrWaVEPXUSkSCxTMZ0NNIYuIlIiloGeCTSGLiJSqpJ7iq4ws6fMbKeZvWRmd5Zpc6WZHTGzbdHj7nLHqpZ0NtBl/yIiJSq5p2gG+Iy7bzGz2cBmM9vk7jtL2j3j7tdXv8SJ3PXDXCIipabsobv7m+6+JVoeAnYBy2pd2IkE7iT0Oy4iIkVOaiDazLoIbxj9XJndl5nZdjN7wszOm+T1682sx8x6+vv7T7rYnGzgKM9FRIpVHOhmNgv4PvBpdx8s2b0FWOXuFwJfBX5Y7hjuvsHdu929u7Ozc7o1466fzhURKVVRoJtZijDMH3b3x0r3u/ugux+Nln8MpMxsUVUrLZDVkIuIyASVzHIx4AFgl7t/aZI2Z0TtMLO10XEPVrPQQoFryEVEpFQls1wuBz4MvGBm26JtnwNWArj7fcBNwCfMLAMcB252d69BvQAEGnIREZlgykB3918AJ0xPd/8a8LVqFTWVINCQi4hIqVhebhlOW6x3FSIiby0xDXTUQxcRKRHPQNeQi4jIBPEMdHd9KSoiUiK2ga4OuohIsZgGusbQRURKxTTQNeQiIlIqloGuH+cSEZkoloHuGnIREZkgloEeuJNUoIuIFIlloGcDJxHLykVEaieWsRg4mHroIiJFYhnoriEXEZEJYhnoWf04l4jIBLEM9CBwDbmIiJSIZ6DrBhciIhPENNA15CIiUqqSe4quMLOnzGynmb1kZneWaWNm9hUz6zWzHWZ2cW3KDQW6SbSIyASV3FM0A3zG3beY2Wxgs5ltcvedBW3eD5wTPS4FvhE910QQQEJddBGRIlP20N39TXffEi0PAbuAZSXNbgS+6aFfAvPMbGnVq41oyEVEZKKTGkM3sy7gIuC5kl3LgD0F63uZGPqY2Xoz6zGznv7+/pOrtIAu/RcRmajiQDezWcD3gU+7++B03szdN7h7t7t3d3Z2TucQuLuuFBURKaOiQDezFGGYP+zuj5Vpsg9YUbC+PNpWde7hs74UFREpVsksFwMeAHa5+5cmabYR+Eg022UdcMTd36xinXlBlOjJWE64FBGpnUpmuVwOfBh4wcy2Rds+B6wEcPf7gB8D1wK9wDDw0eqXGspGga4hFxGRYlMGurv/Ajhherq7A5+sVlEnfq/wWUMuIiLFYjdwkQ005CIiUk7sYjE3hq4euohIsRgGevisMXQRkWLxC/TckIvyXESkSPwCPTfkomv/RUSKxDDQw2cNuYiIFIthoOeGXBToIiKFYhvoGnERESkWw0APnzVtUUSkWPwCPdCXoiIi5cQv0DXkIiJSVuwCffzSfyW6iEih2AW6pi2KiJQXu0B3DbmIiJQVu0DPah66iEhZsQv0IAifNeQiIlIsfoGuIRcRkbIquafov5hZn5m9OMn+K83siJltix53V7/MceP3FFWii4gUquSeog8CXwO+eYI2z7j79VWpaAq6UlREpLwpe+ju/nPg0GmopSK5eejKcxGRYtUaQ7/MzLab2RNmdt5kjcxsvZn1mFlPf3//tN7INeQiIlJWNQJ9C7DK3S8Evgr8cLKG7r7B3bvdvbuzs3Nab6YhFxGR8k450N190N2PRss/BlJmtuiUK5uEhlxERMo75UA3szMsmhRuZmujYx481eNOxnVhkYhIWVPOcjGzfwOuBBaZ2V7g74AUgLvfB9wEfMLMMsBx4GbPpW4N5IdcNIYuIlJkykB391um2P81wmmNp0VWFxaJiJQV4ytFlegiIoViF+iuQBcRKSt2gZ6NfpxL89BFRIrFLtBzQy7qoIuIFItfoAcachERKSd+gR5NW9SQi4hIsdgF+hlz27juD5Yyu72SH4oUEWkesUvFS1Yt4JJVC+pdhojIW07seugiIlKeAl1EpEEo0EVEGoQCXUSkQSjQRUQahAJdRKRBKNBFRBqEAl1EpEFYDW8udOI3NusHXp/myxcBB6pYTlw043nrnJuDzrlyq9y9s9yOugX6qTCzHnfvrncdp1sznrfOuTnonKtDQy4iIg1CgS4i0iDiGugb6l1AnTTjeeucm4POuQpiOYYuIiITxbWHLiIiJRToIiINInaBbmbXmNkrZtZrZn9T73qqxcz+xcz6zOzFgm0LzGyTmf06ep4fbTcz+0r0Z7DDzC6uX+XTZ2YrzOwpM9tpZi+Z2Z3R9oY9bzNrN7PnzWx7dM6fj7afZWbPRef2qJm1RtvbovXeaH9XPes/FWaWNLOtZvZ4tN7Q52xmu83sBTPbZmY90baafrZjFehmlgS+DrwfOBe4xczOrW9VVfMgcE3Jtr8Bfubu5wA/i9YhPP9zosd64BunqcZqywCfcfdzgXXAJ6P/no183qPA1e5+IbAGuMbM1gFfBO5199XAYeD2qP3twOFo+71Ru7i6E9hVsN4M53yVu68pmG9e28+2u8fmAVwG/KRg/S7grnrXVcXz6wJeLFh/BVgaLS8FXomW/wm4pVy7OD+Afwfe2yznDcwAtgCXEl4x2BJtz3/OgZ8Al0XLLVE7q3ft0zjX5VGAXQ08DlgTnPNuYFHJtpp+tmPVQweWAXsK1vdG2xrVEnd/M1r+PbAkWm64P4fon9UXAc/R4OcdDT1sA/qATcBrwIC7Z6ImheeVP+do/xFg4emtuCq+DHwWCKL1hTT+OTvwUzPbbGbro201/WzH7ibRzcrd3cwaco6pmc0Cvg982t0HzSy/rxHP292zwBozmwf8AHhnnUuqKTO7Huhz981mdmW96zmNrnD3fWa2GNhkZi8X7qzFZztuPfR9wIqC9eXRtka138yWAkTPfdH2hvlzMLMUYZg/7O6PRZsb/rwB3H0AeIpwuGGemeU6WIXnlT/naP9c4OBpLvVUXQ7cYGa7gUcIh13+kcY+Z9x9X/TcR/gX91pq/NmOW6D/Cjgn+na8FbgZ2FjnmmppI3BrtHwr4RhzbvtHom/G1wFHCv4ZFxsWdsUfAHa5+5cKdjXseZtZZ9Qzx8w6CL8z2EUY7DdFzUrPOfdncRPwpEeDrHHh7ne5+3J37yL8f/ZJd/8QDXzOZjbTzGbnloH3AS9S6892vb84mMYXDdcCrxKOO/6vetdTxfP6N+BNIE04fnY74bjhz4BfA/8JLIjaGuFsn9eAF4Duetc/zXO+gnCccQewLXpc28jnDVwAbI3O+UXg7mj72cDzQC/wXaAt2t4erfdG+8+u9zmc4vlfCTze6Occndv26PFSLqtq/dnWpf8iIg0ibkMuIiIyCQW6iEiDUKCLiDQIBbqISINQoIuINAgFuohIg1Cgi4g0iP8PbtLELYiBvvwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = nor2_rpre\n",
        "#x1 =array_rain_fall_npy\n",
        "y = nor2_rop\n",
        "#a=x.detach().numpy()\n",
        "#b=y.detach().numpy() \n",
        "#z=predicted[:20]\n",
        "#y_score = z.detach().numpy()\n",
        "print(x)\n",
        "print(y)\n",
        "#nn_fpr, nn_tpr, nn_thresholds = roc_curve(a, y_score)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "with torch.no_grad():\n",
        "  plt.plot(x)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNTjlt77SEcL"
      },
      "outputs": [],
      "source": [
        "print(RATE_Predicted_HBF)\n",
        "#np_arr = RATE_Predicted_HBF.detach().cpu().numpy()\n",
        "import torch\n",
        "np_arr =RATE_Predicted_HBF.detach().numpy()\n",
        "print(np_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "4WCS6KwvSSh8",
        "outputId": "2ca82cd4-6395-424f-9a75-59e7ab9fdca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5.3411093 5.3133273 5.3411093 5.3133273 5.3411093 5.3133273 5.3411093\n",
            " 5.3133273]\n",
            "[1.5574385 1.5623521 3.9236794 3.855479  3.924     3.8549504 3.9369183\n",
            " 3.867689 ]\n",
            "[1 1 1 1 1 1 1 1]\n",
            "[0 0 0 0 0 0 0 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py:990: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d0ffc3bd0a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m## Score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mscore_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_tpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mscore_roc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_roc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         return _average_binary_score(\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_fpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m\"\"\"Binary roc auc score.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    338\u001b[0m             \u001b[0;34m\"Only one class present in y_true. ROC AUC score \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"is not defined in that case.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#from model import AI_Net\n",
        "from operator import add\n",
        "#from crf import apply_crf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "x = np.array(R_optimum_HBF)\n",
        "\n",
        "y = np.array(R_predicted_HBF)\n",
        "#a=x.detach().numpy()\n",
        "#b=y.detach().numpy() \n",
        "z=predicted[:20]\n",
        "y_score = z.detach().numpy()\n",
        "\n",
        "y_true = x\n",
        "y_pred = y\n",
        "\n",
        "y_pred = y_pred > 5.25\n",
        "y_pred = y_pred.reshape(-1)\n",
        "y_pred = y_pred.astype(np.uint8)\n",
        "\n",
        "y_true = y_true > 5.29\n",
        "y_true = y_true.reshape(-1)\n",
        "y_true = y_true.astype(np.uint8)\n",
        "print(x)\n",
        "print(y)\n",
        "print(y_true)\n",
        "print(y_pred)\n",
        "## Score\n",
        "score_fpr, score_tpr, _ = roc_curve(y_true,y_pred)\n",
        "score_roc_auc = roc_auc_score(y_true, y_pred)\n",
        "print(score_roc_auc)\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "with torch.no_grad():\n",
        "  plt.plot(score_fpr, score_tpr)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "0aTUZ2kuSeCz",
        "outputId": "b712dfad-8566-4b47-e9cf-2dd6faf6cb16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[500   0]\n",
            " [ 91 409]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import sklearn.metrics\n",
        "\n",
        "\n",
        "\n",
        "r = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
        "print(r)\n",
        "import seaborn as sns\n",
        "\n",
        "ax = sns.heatmap(r, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['False','True'])\n",
        "ax.yaxis.set_ticklabels(['False','True'])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVCmbkZZSizz"
      },
      "outputs": [],
      "source": [
        "#RATE_Optimum_HBF\n",
        "#RATE_Predicted_HBF\n",
        "#my_testloader\n",
        "#_, predicted\n",
        "#pred1_reg, pred2_reg, pred_class\n",
        "#testInputs_Reg\n",
        "#Model_m_task\n",
        "#R_optimum_HBF\n",
        "#y_pred.reshape(len(y_pred),1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkqfAGAUSqzi",
        "outputId": "96f18144-4d16-43f6-e56b-950af48516f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor(1.5599), tensor(2.7247), tensor(3.1130), tensor(3.3103)]\n"
          ]
        }
      ],
      "source": [
        "print(RATE_Predicted_HBF1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "4SsFlIE8lKCL",
        "outputId": "8c968daf-9680-46a2-d165-0aad6f92cc82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1024, 128])\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e644027c8056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRSSI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'out1' is not defined"
          ]
        }
      ],
      "source": [
        "print(RSSI.shape)\n",
        "#print(out1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "hSxEIK_sv0x9",
        "outputId": "d98ea1c8-3794-4d93-e4c4-13cfdc7f50fd"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-61ffd3131638>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    self.hidden_dim = n_hidden\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "#bilstm\n",
        "\n",
        "        self.hidden_dim = n_hidden\n",
        "        self.batch_size = 1000\n",
        "\n",
        "        self.word_embeddings = nn.Embedding.from_pretrained(0.5, freeze=True)\n",
        "\n",
        "        self.lstm = nn.LSTM(128, hidden_dim,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.lstm = nn.LSTM(64, hidden_dim,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.lstm = nn.LSTM(32, hidden_dim,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p_dropout)\n",
        "        self.fc = nn.Linear(2 * hidden_dim, label_size=5)\n",
        "        self.act = nn.Softmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "O16HGMEE-oGR",
        "outputId": "0746f4c7-4e67-40f5-ee68-df5dfd7c8802"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-063f1013dbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRSSI_N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RSSI_N' is not defined"
          ]
        }
      ],
      "source": [
        "n=RSSI_N\n",
        "print(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoScvL0ZKVor",
        "outputId": "19a439df-8601-4a48-da3b-0962d4b6478c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 128)\n"
          ]
        }
      ],
      "source": [
        "file3=np.load('/content/drive/MyDrive/HBF-Net-main/pcaorpca.npy')\n",
        "a4=np.abs(file3)\n",
        "a5=np.max(a4)\n",
        "a6=np.min(a4)\n",
        "a7=(a4-a6)/(a5-a6)\n",
        "RSSI_ex= a7[:64, (Us * Mr) + (Us * K):(Us * Mr) + (2 * Us * K)].real.astype(float)\n",
        "print(RSSI_ex.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y=np.load(\"/content/drive/MyDrive/HBF-Net-main/DataBase_dataSet64x8x4_130dB_0129201820.npy\")"
      ],
      "metadata": {
        "id": "k-kU65sDZ8f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl-dMYogIHCK"
      },
      "outputs": [],
      "source": [
        "\n",
        "RSSI_N = y[:, (Us * Mr) + (Us * K):(Us * Mr) + (2 * Us * K)].real.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(RSSI_N.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlSfyixyyo0E",
        "outputId": "febddec5-69e8-4024-91c2-22b53257d2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10080, 128)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}